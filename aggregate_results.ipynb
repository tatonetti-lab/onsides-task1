{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = './results/evals'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_files = set()\n",
    "overall_results_df = None\n",
    "results_files_columns = ['method', 'model', 'system', 'prompt', 'temperature', 'run', 'dataset']\n",
    "\n",
    "for results_file in sorted(os.listdir(results_dir)):\n",
    "    \n",
    "    results_file_parts = results_file.split('.csv')[0].split('_')\n",
    "    \n",
    "    system, prompt, temperature, run = ['NA']*4\n",
    "\n",
    "    if results_file_parts[0] in ('code-llama-34b', 'Mixtral-8x7B-Instruct-v0.1'):\n",
    "        method = 'LLM'\n",
    "        model = results_file_parts[0]\n",
    "        prompt, system, temperature = results_file_parts[1:4]\n",
    "        dataset = results_file_parts[4]\n",
    "        run = results_file_parts[5]\n",
    "    elif results_file_parts[0] == 'OpenAI':\n",
    "        method = 'LLM'\n",
    "        model = results_file_parts[1]\n",
    "        prompt, system, temperature = results_file_parts[2:5]\n",
    "        dataset = results_file_parts[5]\n",
    "        run = results_file_parts[6]\n",
    "    elif results_file_parts[0] == 'exact':\n",
    "        method = results_file_parts[0]\n",
    "        model = 'exact'\n",
    "        dataset = results_file_parts[1]\n",
    "    elif results_file_parts[0] == 'deepcadrme':\n",
    "        method = 'BERT'\n",
    "        model = 'deepcadrme'\n",
    "        system = results_file_parts[1]\n",
    "        dataset = results_file_parts[2]\n",
    "    elif results_file_parts[0] in ('granular', 'overall', 'ember-v1'):\n",
    "        continue\n",
    "    else:\n",
    "        raise Exception(results_file_parts[0])\n",
    "\n",
    "    results_files.add((method, model, system, prompt, temperature, run, dataset))\n",
    "    \n",
    "results_files_df = pd.DataFrame(results_files, columns=results_files_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4-1106-preview pharmexpert-v0 fatal-prompt-v2\n",
      "./results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp1.5_train_run0_lenient_overall.csv\n",
      "gpt-4-1106-preview pharmexpert-v1 fatal-prompt-v2\n",
      "./results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_test_run0_ember-v1_overall.csv\n",
      "gpt-4-1106-preview pharmexpert-v0 gpt-written-prompt\n",
      "./results/evals/OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_test_run0_ember-v1_overall.csv\n",
      "gpt-4-1106-preview pharmexpert-v0 only-positives-v0\n",
      "./results/evals/OpenAI_gpt-4-1106-preview_only-positives-v0_pharmexpert-v0_temp0_test_run0_ember-v1_overall.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18406, 19)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for method, model, system, prompt, temperature, run, dataset in results_files:\n",
    "    for evaltype in ('strict', 'lenient', 'ember-v1'):\n",
    "        if model == 'exact':\n",
    "            if evaltype == 'ember-v1':\n",
    "                continue\n",
    "            else:\n",
    "                overall_results_file = '_'.join([model, dataset, evaltype, 'overall.csv'])\n",
    "        elif model == 'deepcadrme':\n",
    "            if evaltype == 'ember-v1':\n",
    "                continue\n",
    "            else:\n",
    "                overall_results_file = '_'.join([model, system, dataset, evaltype, 'overall.csv'])\n",
    "        elif model.startswith('gpt'):\n",
    "            overall_results_file = '_'.join(['OpenAI', model, prompt, system, temperature, dataset, run, evaltype, 'overall.csv'])\n",
    "        else:\n",
    "            overall_results_file = '_'.join([model, prompt, system, temperature, dataset, run, evaltype, 'overall.csv'])\n",
    "        # overall_results_file = results_file.replace('.csv', f\"_{evaltype}_overall.csv\")\n",
    "        \n",
    "        if not os.path.exists(os.path.join(results_dir, overall_results_file)):\n",
    "            print(model, system, prompt)\n",
    "            print(os.path.join(results_dir, overall_results_file))\n",
    "            continue\n",
    "        \n",
    "        res = pd.read_csv(os.path.join(results_dir, overall_results_file), index_col=0)\n",
    "        \n",
    "        for name, colval in zip(results_files_columns, list(results_files)[-1]):\n",
    "            res.insert(0, name, [colval]*res.shape[0])\n",
    "        res.insert(0, 'evaltype', [evaltype]*res.shape[0])\n",
    "        \n",
    "        if overall_results_df is None:\n",
    "            overall_results_df = res\n",
    "        else:\n",
    "            overall_results_df = pd.concat([overall_results_df, res])\n",
    "\n",
    "overall_results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>model</th>\n",
       "      <th>system</th>\n",
       "      <th>prompt</th>\n",
       "      <th>temperature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"14\" valign=\"top\">test</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">BERT</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">deepcadrme</th>\n",
       "      <th>002</th>\n",
       "      <th>NA</th>\n",
       "      <th>NA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005</th>\n",
       "      <th>NA</th>\n",
       "      <th>NA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>010</th>\n",
       "      <th>NA</th>\n",
       "      <th>NA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>015</th>\n",
       "      <th>NA</th>\n",
       "      <th>NA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>025</th>\n",
       "      <th>NA</th>\n",
       "      <th>NA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>050</th>\n",
       "      <th>NA</th>\n",
       "      <th>NA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>075</th>\n",
       "      <th>NA</th>\n",
       "      <th>NA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <th>NA</th>\n",
       "      <th>NA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">LLM</th>\n",
       "      <th>gpt-3.5-turbo-0125</th>\n",
       "      <th>pharmexpert-v1</th>\n",
       "      <th>fatal-prompt-v2</th>\n",
       "      <th>temp0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">gpt-4-1106-preview</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">pharmexpert-v0</th>\n",
       "      <th>gpt-written-prompt</th>\n",
       "      <th>temp0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>only-positives-v0</th>\n",
       "      <th>temp0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pharmexpert-v1</th>\n",
       "      <th>fatal-prompt-v2</th>\n",
       "      <th>temp0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fatal-prompt-v3</th>\n",
       "      <th>temp0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact</th>\n",
       "      <th>exact</th>\n",
       "      <th>NA</th>\n",
       "      <th>NA</th>\n",
       "      <th>NA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">train</th>\n",
       "      <th rowspan=\"15\" valign=\"top\">LLM</th>\n",
       "      <th>Mixtral-8x7B-Instruct-v0.1</th>\n",
       "      <th>pharmexpert-v0</th>\n",
       "      <th>fatal-prompt-v2</th>\n",
       "      <th>temp0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">code-llama-34b</th>\n",
       "      <th>pharmexpert-v0</th>\n",
       "      <th>fatal-prompt-v2</th>\n",
       "      <th>temp0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pharmexpert-v1</th>\n",
       "      <th>fatal-prompt-v2</th>\n",
       "      <th>temp0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">gpt-3.5-turbo-0125</th>\n",
       "      <th>no-system-prompt</th>\n",
       "      <th>fatal-prompt-v2</th>\n",
       "      <th>temp0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pharmexpert-v0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">fatal-prompt-v2</th>\n",
       "      <th>temp0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp0.5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pharmexpert-v1</th>\n",
       "      <th>fatal-prompt-v2</th>\n",
       "      <th>temp0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">gpt-4-1106-preview</th>\n",
       "      <th>no-system-prompt</th>\n",
       "      <th>fatal-prompt-v2</th>\n",
       "      <th>temp0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">pharmexpert-v0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">fatal-prompt-v2</th>\n",
       "      <th>temp0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp0.5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp1.0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp1.5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pharmexpert-v1</th>\n",
       "      <th>fatal-prompt-v2</th>\n",
       "      <th>temp0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fatal-prompt-v3</th>\n",
       "      <th>temp0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <th>pharmexpert-v0</th>\n",
       "      <th>gpt-written-prompt</th>\n",
       "      <th>temp0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact</th>\n",
       "      <th>exact</th>\n",
       "      <th>NA</th>\n",
       "      <th>NA</th>\n",
       "      <th>NA</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           run\n",
       "dataset method model                      system           prompt             temperature     \n",
       "test    BERT   deepcadrme                 002              NA                 NA             1\n",
       "                                          005              NA                 NA             1\n",
       "                                          010              NA                 NA             1\n",
       "                                          015              NA                 NA             1\n",
       "                                          025              NA                 NA             1\n",
       "                                          050              NA                 NA             1\n",
       "                                          075              NA                 NA             1\n",
       "                                          100              NA                 NA             1\n",
       "        LLM    gpt-3.5-turbo-0125         pharmexpert-v1   fatal-prompt-v2    temp0          3\n",
       "               gpt-4-1106-preview         pharmexpert-v0   gpt-written-prompt temp0          1\n",
       "                                                           only-positives-v0  temp0          1\n",
       "                                          pharmexpert-v1   fatal-prompt-v2    temp0          2\n",
       "                                                           fatal-prompt-v3    temp0          1\n",
       "        exact  exact                      NA               NA                 NA             1\n",
       "train   LLM    Mixtral-8x7B-Instruct-v0.1 pharmexpert-v0   fatal-prompt-v2    temp0          1\n",
       "               code-llama-34b             pharmexpert-v0   fatal-prompt-v2    temp0          1\n",
       "                                          pharmexpert-v1   fatal-prompt-v2    temp0          1\n",
       "               gpt-3.5-turbo-0125         no-system-prompt fatal-prompt-v2    temp0          3\n",
       "                                          pharmexpert-v0   fatal-prompt-v2    temp0          3\n",
       "                                                                              temp0.5        3\n",
       "                                          pharmexpert-v1   fatal-prompt-v2    temp0          4\n",
       "               gpt-4-1106-preview         no-system-prompt fatal-prompt-v2    temp0          3\n",
       "                                          pharmexpert-v0   fatal-prompt-v2    temp0          3\n",
       "                                                                              temp0.5        3\n",
       "                                                                              temp1.0        3\n",
       "                                                                              temp1.5        1\n",
       "                                          pharmexpert-v1   fatal-prompt-v2    temp0          5\n",
       "                                                           fatal-prompt-v3    temp0          1\n",
       "               gpt-4-turbo-preview        pharmexpert-v0   gpt-written-prompt temp0          3\n",
       "        exact  exact                      NA               NA                 NA             1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_files_df.groupby(['dataset', 'method', 'model', 'system', 'prompt', 'temperature']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evaltype</th>\n",
       "      <th>dataset</th>\n",
       "      <th>run</th>\n",
       "      <th>temperature</th>\n",
       "      <th>prompt</th>\n",
       "      <th>system</th>\n",
       "      <th>model</th>\n",
       "      <th>method</th>\n",
       "      <th>section</th>\n",
       "      <th>ade_type</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>micro_precision</th>\n",
       "      <th>micro_recall</th>\n",
       "      <th>micro_f1</th>\n",
       "      <th>macro_precision</th>\n",
       "      <th>macro_recall</th>\n",
       "      <th>macro_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>strict</td>\n",
       "      <td>train</td>\n",
       "      <td>run0</td>\n",
       "      <td>temp0</td>\n",
       "      <td>gpt-written-prompt</td>\n",
       "      <td>pharmexpert-v0</td>\n",
       "      <td>gpt-4-turbo-preview</td>\n",
       "      <td>LLM</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>all</td>\n",
       "      <td>2577.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>2832.0</td>\n",
       "      <td>0.870020</td>\n",
       "      <td>0.476428</td>\n",
       "      <td>0.615697</td>\n",
       "      <td>0.826498</td>\n",
       "      <td>0.547706</td>\n",
       "      <td>0.650816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strict</td>\n",
       "      <td>train</td>\n",
       "      <td>run0</td>\n",
       "      <td>temp0</td>\n",
       "      <td>gpt-written-prompt</td>\n",
       "      <td>pharmexpert-v0</td>\n",
       "      <td>gpt-4-turbo-preview</td>\n",
       "      <td>LLM</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>discontinuous</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>379.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035179</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strict</td>\n",
       "      <td>train</td>\n",
       "      <td>run0</td>\n",
       "      <td>temp0</td>\n",
       "      <td>gpt-written-prompt</td>\n",
       "      <td>pharmexpert-v0</td>\n",
       "      <td>gpt-4-turbo-preview</td>\n",
       "      <td>LLM</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>exact-meddra</td>\n",
       "      <td>2325.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1838.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.558491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.625631</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>strict</td>\n",
       "      <td>train</td>\n",
       "      <td>run0</td>\n",
       "      <td>temp0</td>\n",
       "      <td>gpt-written-prompt</td>\n",
       "      <td>pharmexpert-v0</td>\n",
       "      <td>gpt-4-turbo-preview</td>\n",
       "      <td>LLM</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>hypothetical</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.306034</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strict</td>\n",
       "      <td>train</td>\n",
       "      <td>run0</td>\n",
       "      <td>temp0</td>\n",
       "      <td>gpt-written-prompt</td>\n",
       "      <td>pharmexpert-v0</td>\n",
       "      <td>gpt-4-turbo-preview</td>\n",
       "      <td>LLM</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>negated</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.191781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.164762</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ember-v1</td>\n",
       "      <td>train</td>\n",
       "      <td>run0</td>\n",
       "      <td>temp0</td>\n",
       "      <td>gpt-written-prompt</td>\n",
       "      <td>pharmexpert-v0</td>\n",
       "      <td>gpt-4-turbo-preview</td>\n",
       "      <td>LLM</td>\n",
       "      <td>warnings and precautions</td>\n",
       "      <td>discontinuous</td>\n",
       "      <td>343.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.209914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.263334</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ember-v1</td>\n",
       "      <td>train</td>\n",
       "      <td>run0</td>\n",
       "      <td>temp0</td>\n",
       "      <td>gpt-written-prompt</td>\n",
       "      <td>pharmexpert-v0</td>\n",
       "      <td>gpt-4-turbo-preview</td>\n",
       "      <td>LLM</td>\n",
       "      <td>warnings and precautions</td>\n",
       "      <td>exact-meddra</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578699</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ember-v1</td>\n",
       "      <td>train</td>\n",
       "      <td>run0</td>\n",
       "      <td>temp0</td>\n",
       "      <td>gpt-written-prompt</td>\n",
       "      <td>pharmexpert-v0</td>\n",
       "      <td>gpt-4-turbo-preview</td>\n",
       "      <td>LLM</td>\n",
       "      <td>warnings and precautions</td>\n",
       "      <td>negated</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>590.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ember-v1</td>\n",
       "      <td>train</td>\n",
       "      <td>run0</td>\n",
       "      <td>temp0</td>\n",
       "      <td>gpt-written-prompt</td>\n",
       "      <td>pharmexpert-v0</td>\n",
       "      <td>gpt-4-turbo-preview</td>\n",
       "      <td>LLM</td>\n",
       "      <td>warnings and precautions</td>\n",
       "      <td>non-meddra</td>\n",
       "      <td>1301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>704.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.648878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.623480</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ember-v1</td>\n",
       "      <td>train</td>\n",
       "      <td>run0</td>\n",
       "      <td>temp0</td>\n",
       "      <td>gpt-written-prompt</td>\n",
       "      <td>pharmexpert-v0</td>\n",
       "      <td>gpt-4-turbo-preview</td>\n",
       "      <td>LLM</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>7863.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>0.934958</td>\n",
       "      <td>0.965259</td>\n",
       "      <td>0.936620</td>\n",
       "      <td>0.928568</td>\n",
       "      <td>0.926201</td>\n",
       "      <td>0.916107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18406 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    evaltype dataset   run temperature              prompt          system  \\\n",
       "0     strict   train  run0       temp0  gpt-written-prompt  pharmexpert-v0   \n",
       "1     strict   train  run0       temp0  gpt-written-prompt  pharmexpert-v0   \n",
       "2     strict   train  run0       temp0  gpt-written-prompt  pharmexpert-v0   \n",
       "3     strict   train  run0       temp0  gpt-written-prompt  pharmexpert-v0   \n",
       "4     strict   train  run0       temp0  gpt-written-prompt  pharmexpert-v0   \n",
       "..       ...     ...   ...         ...                 ...             ...   \n",
       "16  ember-v1   train  run0       temp0  gpt-written-prompt  pharmexpert-v0   \n",
       "17  ember-v1   train  run0       temp0  gpt-written-prompt  pharmexpert-v0   \n",
       "18  ember-v1   train  run0       temp0  gpt-written-prompt  pharmexpert-v0   \n",
       "19  ember-v1   train  run0       temp0  gpt-written-prompt  pharmexpert-v0   \n",
       "0   ember-v1   train  run0       temp0  gpt-written-prompt  pharmexpert-v0   \n",
       "\n",
       "                  model method                   section       ade_type  \\\n",
       "0   gpt-4-turbo-preview    LLM         adverse reactions            all   \n",
       "1   gpt-4-turbo-preview    LLM         adverse reactions  discontinuous   \n",
       "2   gpt-4-turbo-preview    LLM         adverse reactions   exact-meddra   \n",
       "3   gpt-4-turbo-preview    LLM         adverse reactions   hypothetical   \n",
       "4   gpt-4-turbo-preview    LLM         adverse reactions        negated   \n",
       "..                  ...    ...                       ...            ...   \n",
       "16  gpt-4-turbo-preview    LLM  warnings and precautions  discontinuous   \n",
       "17  gpt-4-turbo-preview    LLM  warnings and precautions   exact-meddra   \n",
       "18  gpt-4-turbo-preview    LLM  warnings and precautions        negated   \n",
       "19  gpt-4-turbo-preview    LLM  warnings and precautions     non-meddra   \n",
       "0   gpt-4-turbo-preview    LLM                       all            all   \n",
       "\n",
       "        tp     fp      fn  micro_precision  micro_recall  micro_f1  \\\n",
       "0   2577.0  385.0  2832.0         0.870020      0.476428  0.615697   \n",
       "1     18.0    NaN   379.0              NaN      0.045340       NaN   \n",
       "2   2325.0    NaN  1838.0              NaN      0.558491       NaN   \n",
       "3     20.0    NaN    60.0              NaN      0.250000       NaN   \n",
       "4     14.0    NaN    59.0              NaN      0.191781       NaN   \n",
       "..     ...    ...     ...              ...           ...       ...   \n",
       "16   343.0    NaN  1291.0              NaN      0.209914       NaN   \n",
       "17  1144.0    NaN   600.0              NaN      0.655963       NaN   \n",
       "18    49.0    NaN   590.0              NaN      0.076682       NaN   \n",
       "19  1301.0    NaN   704.0              NaN      0.648878       NaN   \n",
       "0   7863.0  547.0   283.0         0.934958      0.965259  0.936620   \n",
       "\n",
       "    macro_precision  macro_recall  macro_f1  \n",
       "0          0.826498      0.547706  0.650816  \n",
       "1               NaN      0.035179       NaN  \n",
       "2               NaN      0.625631       NaN  \n",
       "3               NaN      0.306034       NaN  \n",
       "4               NaN      0.164762       NaN  \n",
       "..              ...           ...       ...  \n",
       "16              NaN      0.263334       NaN  \n",
       "17              NaN      0.578699       NaN  \n",
       "18              NaN      0.114180       NaN  \n",
       "19              NaN      0.623480       NaN  \n",
       "0          0.928568      0.926201  0.916107  \n",
       "\n",
       "[18406 rows x 19 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>ade_type</th>\n",
       "      <th>section</th>\n",
       "      <th>method</th>\n",
       "      <th>model</th>\n",
       "      <th>system</th>\n",
       "      <th>prompt</th>\n",
       "      <th>temperature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <th>all</th>\n",
       "      <th>adverse reactions</th>\n",
       "      <th>LLM</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <th>pharmexpert-v0</th>\n",
       "      <th>gpt-written-prompt</th>\n",
       "      <th>temp0</th>\n",
       "      <td>317</td>\n",
       "      <td>0.844977</td>\n",
       "      <td>0.364051</td>\n",
       "      <td>0.957095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                             count  \\\n",
       "dataset ade_type section           method model               system         prompt             temperature          \n",
       "train   all      adverse reactions LLM    gpt-4-turbo-preview pharmexpert-v0 gpt-written-prompt temp0          317   \n",
       "\n",
       "                                                                                                                 mean  \\\n",
       "dataset ade_type section           method model               system         prompt             temperature             \n",
       "train   all      adverse reactions LLM    gpt-4-turbo-preview pharmexpert-v0 gpt-written-prompt temp0        0.844977   \n",
       "\n",
       "                                                                                                                  min  \\\n",
       "dataset ade_type section           method model               system         prompt             temperature             \n",
       "train   all      adverse reactions LLM    gpt-4-turbo-preview pharmexpert-v0 gpt-written-prompt temp0        0.364051   \n",
       "\n",
       "                                                                                                                  max  \n",
       "dataset ade_type section           method model               system         prompt             temperature            \n",
       "train   all      adverse reactions LLM    gpt-4-turbo-preview pharmexpert-v0 gpt-written-prompt temp0        0.957095  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default eval\n",
    "groupbycols = ['dataset', 'ade_type', 'section', 'method', 'model', 'system', 'prompt', 'temperature']\n",
    "additional_querystr = \" & ade_type=='all'\"\n",
    "\n",
    "# evaluate the prompt\n",
    "# found that pharmexpert-v1 is working a bit better than the others\n",
    "# groupbycols = ['dataset', 'ade_type', 'section', 'prompt', 'method']\n",
    "# additional_querystr = \" & model != 'code-llama-34b' & method == 'LLM'\"\n",
    "\n",
    "# compare ade_types\n",
    "# groupbycols = ['ade_type', 'dataset', 'ade_type', 'section', 'method', 'model', 'system', 'prompt']\n",
    "# additional_querystr = \"\"\n",
    "\n",
    "querystr = \"evaltype=='lenient' & dataset=='train' & section == 'adverse reactions'\" + additional_querystr\n",
    "metric = 'f1'\n",
    "overall_results_df.query(querystr).groupby(groupbycols)[f\"macro_{metric}\"].agg(['count', 'mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>ade_type</th>\n",
       "      <th>section</th>\n",
       "      <th>method</th>\n",
       "      <th>model</th>\n",
       "      <th>system</th>\n",
       "      <th>prompt</th>\n",
       "      <th>temperature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <th>all</th>\n",
       "      <th>adverse reactions</th>\n",
       "      <th>LLM</th>\n",
       "      <th>gpt-4-turbo-preview</th>\n",
       "      <th>pharmexpert-v0</th>\n",
       "      <th>gpt-written-prompt</th>\n",
       "      <th>temp0</th>\n",
       "      <td>317</td>\n",
       "      <td>0.830978</td>\n",
       "      <td>0.185248</td>\n",
       "      <td>0.959057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                             count  \\\n",
       "dataset ade_type section           method model               system         prompt             temperature          \n",
       "train   all      adverse reactions LLM    gpt-4-turbo-preview pharmexpert-v0 gpt-written-prompt temp0          317   \n",
       "\n",
       "                                                                                                                 mean  \\\n",
       "dataset ade_type section           method model               system         prompt             temperature             \n",
       "train   all      adverse reactions LLM    gpt-4-turbo-preview pharmexpert-v0 gpt-written-prompt temp0        0.830978   \n",
       "\n",
       "                                                                                                                  min  \\\n",
       "dataset ade_type section           method model               system         prompt             temperature             \n",
       "train   all      adverse reactions LLM    gpt-4-turbo-preview pharmexpert-v0 gpt-written-prompt temp0        0.185248   \n",
       "\n",
       "                                                                                                                  max  \n",
       "dataset ade_type section           method model               system         prompt             temperature            \n",
       "train   all      adverse reactions LLM    gpt-4-turbo-preview pharmexpert-v0 gpt-written-prompt temp0        0.959057  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_results_df.query(querystr).groupby(groupbycols)[f\"micro_{metric}\"].agg(['count', 'mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
