{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = './results/evals'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_files = set()\n",
    "overall_results_df = None\n",
    "results_files_columns = ['method', 'model', 'system', 'prompt', 'temperature', 'run', 'dataset']\n",
    "\n",
    "for results_file in sorted(os.listdir(results_dir)):\n",
    "    \n",
    "    results_file_parts = results_file.split('.csv')[0].split('_')\n",
    "    \n",
    "    system, prompt, temperature, run = ['NA']*4\n",
    "\n",
    "    if results_file_parts[0] == 'code-llama-34b':\n",
    "        method = 'LLM'\n",
    "        model = results_file_parts[0]\n",
    "        system, prompt, temperature = results_file_parts[1:4]\n",
    "        dataset = results_file_parts[4]\n",
    "        run = results_file_parts[5]\n",
    "    elif results_file_parts[0] == 'OpenAI':\n",
    "        method = 'LLM'\n",
    "        model = results_file_parts[1]\n",
    "        system, prompt, temperature = results_file_parts[2:5]\n",
    "        dataset = results_file_parts[5]\n",
    "        run = results_file_parts[6]\n",
    "    elif results_file_parts[0] == 'exact':\n",
    "        method = results_file_parts[0]\n",
    "        model = 'exact'\n",
    "        dataset = results_file_parts[1]\n",
    "    elif results_file_parts[0] == 'deepcadrme':\n",
    "        method = 'BERT'\n",
    "        model = 'deepcadrme'\n",
    "        system = results_file_parts[1]\n",
    "        dataset = results_file_parts[2]\n",
    "    elif results_file_parts[0] in ('granular', 'overall'):\n",
    "        continue\n",
    "    else:\n",
    "        raise Exception(results_file_parts[0])\n",
    "\n",
    "    results_files.add([method, model, system, prompt, temperature, run, dataset])\n",
    "    \n",
    "    for evaltype in ('strict', 'lenient'):\n",
    "        overall_results_file = results_file.replace('.csv', f\"_{evaltype}_overall.csv\")\n",
    "        if not os.path.exists(os.path.join(results_dir, overall_results_file)):\n",
    "            continue\n",
    "        res = pd.read_csv(os.path.join(results_dir, overall_results_file), index_col=0)\n",
    "        for name, colval in zip(results_files_columns, results_files[-1]):\n",
    "            res.insert(0, name, [colval]*res.shape[0])\n",
    "        res.insert(0, 'evaltype', [evaltype]*res.shape[0])\n",
    "        \n",
    "        if overall_results_df is None:\n",
    "            overall_results_df = res\n",
    "        else:\n",
    "            overall_results_df = pd.concat([overall_results_df, res])\n",
    "\n",
    "results_files_df = pd.DataFrame(results_files, columns=results_files_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>method</th>\n",
       "      <th>model</th>\n",
       "      <th>system</th>\n",
       "      <th>prompt</th>\n",
       "      <th>temperature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [run]\n",
       "Index: []"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_files_df.groupby(['dataset', 'method', 'model', 'system', 'prompt', 'temperature']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[273], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m querystr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaltype==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlenient\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m & dataset==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m & section == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madverse reactions\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m additional_querystr\n\u001b[1;32m     15\u001b[0m metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 16\u001b[0m \u001b[43moverall_results_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m(querystr)\u001b[38;5;241m.\u001b[39mgroupby(groupbycols)[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39magg([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'query'"
     ]
    }
   ],
   "source": [
    "# default eval\n",
    "groupbycols = ['dataset', 'ade_type', 'section', 'method', 'model', 'system', 'prompt', 'temperature']\n",
    "additional_querystr = \" & ade_type=='all'\"\n",
    "\n",
    "# evaluate the prompt\n",
    "# found that pharmexpert-v1 is working a bit better than the others\n",
    "# groupbycols = ['dataset', 'ade_type', 'section', 'prompt', 'method']\n",
    "# additional_querystr = \" & model != 'code-llama-34b' & method == 'LLM'\"\n",
    "\n",
    "# compare ade_types\n",
    "# groupbycols = ['ade_type', 'dataset', 'ade_type', 'section', 'method', 'model', 'system', 'prompt']\n",
    "# additional_querystr = \"\"\n",
    "\n",
    "querystr = \"evaltype=='lenient' & dataset=='train' & section == 'adverse reactions'\" + additional_querystr\n",
    "metric = 'f1'\n",
    "overall_results_df.query(querystr).groupby(groupbycols)[f\"macro_{metric}\"].agg(['count', 'mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>ade_type</th>\n",
       "      <th>section</th>\n",
       "      <th>method</th>\n",
       "      <th>model</th>\n",
       "      <th>system</th>\n",
       "      <th>prompt</th>\n",
       "      <th>temperature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">train</th>\n",
       "      <th rowspan=\"13\" valign=\"top\">all</th>\n",
       "      <th rowspan=\"13\" valign=\"top\">adverse reactions</th>\n",
       "      <th rowspan=\"12\" valign=\"top\">LLM</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">code-llama-34b</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">fatal-prompt-v2</th>\n",
       "      <th>pharmexpert-v0</th>\n",
       "      <th>temp0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.420294</td>\n",
       "      <td>0.420294</td>\n",
       "      <td>0.420294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pharmexpert-v1</th>\n",
       "      <th>temp0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.429824</td>\n",
       "      <td>0.429824</td>\n",
       "      <td>0.429824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">gpt-3.5-turbo-0125</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">fatal-prompt-v2</th>\n",
       "      <th>no-system-prompt</th>\n",
       "      <th>temp0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.711965</td>\n",
       "      <td>0.703835</td>\n",
       "      <td>0.720075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">pharmexpert-v0</th>\n",
       "      <th>temp0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.775151</td>\n",
       "      <td>0.773829</td>\n",
       "      <td>0.776471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp0.5</th>\n",
       "      <td>3</td>\n",
       "      <td>0.778933</td>\n",
       "      <td>0.772114</td>\n",
       "      <td>0.783626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pharmexpert-v1</th>\n",
       "      <th>temp0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.799266</td>\n",
       "      <td>0.767364</td>\n",
       "      <td>0.822303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">gpt-4-1106-preview</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">fatal-prompt-v2</th>\n",
       "      <th>no-system-prompt</th>\n",
       "      <th>temp0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.894240</td>\n",
       "      <td>0.893668</td>\n",
       "      <td>0.894816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">pharmexpert-v0</th>\n",
       "      <th>temp0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.893306</td>\n",
       "      <td>0.890133</td>\n",
       "      <td>0.897992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp0.5</th>\n",
       "      <td>3</td>\n",
       "      <td>0.894164</td>\n",
       "      <td>0.887528</td>\n",
       "      <td>0.898406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp1.0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.892385</td>\n",
       "      <td>0.888134</td>\n",
       "      <td>0.895062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pharmexpert-v1</th>\n",
       "      <th>temp0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.897691</td>\n",
       "      <td>0.895025</td>\n",
       "      <td>0.901260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fatal-prompt-v3</th>\n",
       "      <th>pharmexpert-v1</th>\n",
       "      <th>temp0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.884542</td>\n",
       "      <td>0.884542</td>\n",
       "      <td>0.884542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact</th>\n",
       "      <th>exact</th>\n",
       "      <th>NA</th>\n",
       "      <th>NA</th>\n",
       "      <th>NA</th>\n",
       "      <td>1</td>\n",
       "      <td>0.835516</td>\n",
       "      <td>0.835516</td>\n",
       "      <td>0.835516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                           count  \\\n",
       "dataset ade_type section           method model              system          prompt           temperature          \n",
       "train   all      adverse reactions LLM    code-llama-34b     fatal-prompt-v2 pharmexpert-v0   temp0            1   \n",
       "                                                                             pharmexpert-v1   temp0            1   \n",
       "                                          gpt-3.5-turbo-0125 fatal-prompt-v2 no-system-prompt temp0            3   \n",
       "                                                                             pharmexpert-v0   temp0            3   \n",
       "                                                                                              temp0.5          3   \n",
       "                                                                             pharmexpert-v1   temp0            4   \n",
       "                                          gpt-4-1106-preview fatal-prompt-v2 no-system-prompt temp0            3   \n",
       "                                                                             pharmexpert-v0   temp0            3   \n",
       "                                                                                              temp0.5          3   \n",
       "                                                                                              temp1.0          3   \n",
       "                                                                             pharmexpert-v1   temp0            5   \n",
       "                                                             fatal-prompt-v3 pharmexpert-v1   temp0            1   \n",
       "                                   exact  exact              NA              NA               NA               1   \n",
       "\n",
       "                                                                                                               mean  \\\n",
       "dataset ade_type section           method model              system          prompt           temperature             \n",
       "train   all      adverse reactions LLM    code-llama-34b     fatal-prompt-v2 pharmexpert-v0   temp0        0.420294   \n",
       "                                                                             pharmexpert-v1   temp0        0.429824   \n",
       "                                          gpt-3.5-turbo-0125 fatal-prompt-v2 no-system-prompt temp0        0.711965   \n",
       "                                                                             pharmexpert-v0   temp0        0.775151   \n",
       "                                                                                              temp0.5      0.778933   \n",
       "                                                                             pharmexpert-v1   temp0        0.799266   \n",
       "                                          gpt-4-1106-preview fatal-prompt-v2 no-system-prompt temp0        0.894240   \n",
       "                                                                             pharmexpert-v0   temp0        0.893306   \n",
       "                                                                                              temp0.5      0.894164   \n",
       "                                                                                              temp1.0      0.892385   \n",
       "                                                                             pharmexpert-v1   temp0        0.897691   \n",
       "                                                             fatal-prompt-v3 pharmexpert-v1   temp0        0.884542   \n",
       "                                   exact  exact              NA              NA               NA           0.835516   \n",
       "\n",
       "                                                                                                                min  \\\n",
       "dataset ade_type section           method model              system          prompt           temperature             \n",
       "train   all      adverse reactions LLM    code-llama-34b     fatal-prompt-v2 pharmexpert-v0   temp0        0.420294   \n",
       "                                                                             pharmexpert-v1   temp0        0.429824   \n",
       "                                          gpt-3.5-turbo-0125 fatal-prompt-v2 no-system-prompt temp0        0.703835   \n",
       "                                                                             pharmexpert-v0   temp0        0.773829   \n",
       "                                                                                              temp0.5      0.772114   \n",
       "                                                                             pharmexpert-v1   temp0        0.767364   \n",
       "                                          gpt-4-1106-preview fatal-prompt-v2 no-system-prompt temp0        0.893668   \n",
       "                                                                             pharmexpert-v0   temp0        0.890133   \n",
       "                                                                                              temp0.5      0.887528   \n",
       "                                                                                              temp1.0      0.888134   \n",
       "                                                                             pharmexpert-v1   temp0        0.895025   \n",
       "                                                             fatal-prompt-v3 pharmexpert-v1   temp0        0.884542   \n",
       "                                   exact  exact              NA              NA               NA           0.835516   \n",
       "\n",
       "                                                                                                                max  \n",
       "dataset ade_type section           method model              system          prompt           temperature            \n",
       "train   all      adverse reactions LLM    code-llama-34b     fatal-prompt-v2 pharmexpert-v0   temp0        0.420294  \n",
       "                                                                             pharmexpert-v1   temp0        0.429824  \n",
       "                                          gpt-3.5-turbo-0125 fatal-prompt-v2 no-system-prompt temp0        0.720075  \n",
       "                                                                             pharmexpert-v0   temp0        0.776471  \n",
       "                                                                                              temp0.5      0.783626  \n",
       "                                                                             pharmexpert-v1   temp0        0.822303  \n",
       "                                          gpt-4-1106-preview fatal-prompt-v2 no-system-prompt temp0        0.894816  \n",
       "                                                                             pharmexpert-v0   temp0        0.897992  \n",
       "                                                                                              temp0.5      0.898406  \n",
       "                                                                                              temp1.0      0.895062  \n",
       "                                                                             pharmexpert-v1   temp0        0.901260  \n",
       "                                                             fatal-prompt-v3 pharmexpert-v1   temp0        0.884542  \n",
       "                                   exact  exact              NA              NA               NA           0.835516  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_results_df.query(querystr).groupby(groupbycols)[f\"micro_{metric}\"].agg(['count', 'mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
