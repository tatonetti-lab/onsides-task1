{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import cos_sim\n",
    "import concurrent\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modules.json: 100%|██████████| 229/229 [00:00<00:00, 1.55MB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 123/123 [00:00<00:00, 1.02MB/s]\n",
      "README.md: 100%|██████████| 84.9k/84.9k [00:00<00:00, 2.05MB/s]\n",
      "sentence_bert_config.json: 100%|██████████| 54.0/54.0 [00:00<00:00, 334kB/s]\n",
      "config.json: 100%|██████████| 663/663 [00:00<00:00, 4.87MB/s]\n",
      "model.safetensors.index.json: 100%|██████████| 22.2k/22.2k [00:00<00:00, 36.0MB/s]\n",
      "model-00001-of-00003.safetensors: 100%|██████████| 4.94G/4.94G [24:27<00:00, 3.37MB/s]\n",
      "model-00002-of-00003.safetensors: 100%|██████████| 5.00G/5.00G [21:26<00:00, 3.89MB/s]\n",
      "model-00003-of-00003.safetensors: 100%|██████████| 4.28G/4.28G [09:52<00:00, 7.22MB/s]\n",
      "Downloading shards: 100%|██████████| 3/3 [55:48<00:00, 1116.02s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:56<00:00, 18.70s/it]\n",
      "tokenizer_config.json: 100%|██████████| 981/981 [00:00<00:00, 3.80MB/s]\n",
      "tokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 2.31MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.80M/1.80M [00:01<00:00, 922kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 624/624 [00:00<00:00, 1.76MB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 271/271 [00:00<00:00, 982kB/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 12.97 GB, other allocations: 526.98 MB, max allowed: 13.57 GB). Tried to allocate 224.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalesforce/SFR-Embedding-Mistral\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(model_name)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm_cpus/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:218\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, cache_folder, trust_remote_code, revision, token, use_auth_token)\u001b[0m\n\u001b[1;32m    215\u001b[0m     device \u001b[38;5;241m=\u001b[39m get_device_name()\n\u001b[1;32m    216\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse pytorch device_name: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(device))\n\u001b[0;32m--> 218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm_cpus/lib/python3.11/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm_cpus/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm_cpus/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 810 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm_cpus/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm_cpus/lib/python3.11/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/llm_cpus/lib/python3.11/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 12.97 GB, other allocations: 526.98 MB, max allowed: 13.57 GB). Tried to allocate 224.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "model_name = 'Salesforce/SFR-Embedding-Mistral'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlapping Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug</th>\n",
       "      <th>adverse_event</th>\n",
       "      <th>comp_term</th>\n",
       "      <th>is_overlapping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XEOMIN</td>\n",
       "      <td>Hypersensitivity</td>\n",
       "      <td>Precautions Dysphagia and</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XEOMIN</td>\n",
       "      <td>Hypersensitivity</td>\n",
       "      <td>reactions to XEOMIN are discussed in greater d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XEOMIN</td>\n",
       "      <td>Dysphagia</td>\n",
       "      <td>Dysphagia and Breathing Difficulties in Treatment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XEOMIN</td>\n",
       "      <td>Dysphagia</td>\n",
       "      <td>Dysphagia and</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XEOMIN</td>\n",
       "      <td>Dysphagia</td>\n",
       "      <td>Dysphagia and Breathing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     drug     adverse_event  \\\n",
       "0  XEOMIN  Hypersensitivity   \n",
       "1  XEOMIN  Hypersensitivity   \n",
       "2  XEOMIN         Dysphagia   \n",
       "3  XEOMIN         Dysphagia   \n",
       "5  XEOMIN         Dysphagia   \n",
       "\n",
       "                                           comp_term  is_overlapping  \n",
       "0                          Precautions Dysphagia and               0  \n",
       "1  reactions to XEOMIN are discussed in greater d...               0  \n",
       "2  Dysphagia and Breathing Difficulties in Treatment               1  \n",
       "3                                      Dysphagia and               1  \n",
       "5                            Dysphagia and Breathing               1  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_data = pd.read_csv('data/overlap_data.csv').drop_duplicates()\n",
    "overlap_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46840, 4)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_data.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "similarities = []\n",
    "for ind, row in enumerate(overlap_data.itertuples()):\n",
    "    if ind > 10:\n",
    "        break\n",
    "    ade_embed = model.encode(row.adverse_event)\n",
    "    comp_term = model.encode(row.comp_term)\n",
    "    similarities.append(cos_sim(ade_embed, comp_term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [45:37<00:00, 27.11s/it]\n"
     ]
    }
   ],
   "source": [
    "drug_ade_embed = {}\n",
    "for drug in tqdm(overlap_data.drug.unique()):\n",
    "    sub_data = overlap_data[overlap_data.drug == drug]\n",
    "    ade_list = list(sub_data.adverse_event.unique())\n",
    "    comp_list = list(sub_data.comp_term.unique())\n",
    "    all_list = ade_list + comp_list\n",
    "    all_embed = model.encode(all_list)\n",
    "    drug_ade_embed[drug] = dict(zip(all_list, all_embed))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:05<00:00, 18.46it/s]\n"
     ]
    }
   ],
   "source": [
    "new_embed = {}\n",
    "for drug, embed_dict in tqdm(drug_ade_embed.items()):\n",
    "    new_embed[drug] = {}\n",
    "    for term, embed in embed_dict.items():\n",
    "        new_embed[drug][term] = [float(x) for x in embed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(new_embed, open('data/drug_ade_embed_modeluae.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(drug_ade_embed, open('data/drug_ade_embed_modeluae.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_embeds = pickle.load(open('data/drug_ade_embed_modeluae.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_embeds = json.load(open('data/drug_ade_embed_modeluae.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = []\n",
    "for row in overlap_data.itertuples():\n",
    "    drug = row.drug\n",
    "    ade = row.adverse_event\n",
    "    comp = row.comp_term\n",
    "    ade_embed = loaded_embeds[drug][ade]\n",
    "    comp_embed = loaded_embeds[drug][comp]\n",
    "    similarities.append(float(cos_sim(ade_embed, comp_embed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_data['similarity'] = similarities\n",
    "overlap_data.to_csv('data/overlap_data_w_similarity_modeluae.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT output compared to manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.6681796"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug_name</th>\n",
       "      <th>section_name</th>\n",
       "      <th>gpt_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KYPROLIS</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>Cardiac Toxicities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KYPROLIS</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>Acute Renal Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KYPROLIS</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>Tumor Lysis Syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KYPROLIS</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>Pulmonary Toxicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KYPROLIS</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>Pulmonary Hypertension</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  drug_name       section_name              gpt_output\n",
       "0  KYPROLIS  adverse reactions      Cardiac Toxicities\n",
       "1  KYPROLIS  adverse reactions     Acute Renal Failure\n",
       "2  KYPROLIS  adverse reactions    Tumor Lysis Syndrome\n",
       "3  KYPROLIS  adverse reactions      Pulmonary Toxicity\n",
       "4  KYPROLIS  adverse reactions  Pulmonary Hypertension"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_output = pd.read_csv('results/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run0.csv',\n",
    "                         usecols = ['drug_name', 'section_name', 'gpt_output'])\n",
    "gpt_output['gpt_output'] = gpt_output['gpt_output'].str.replace('.', '').str.split(', ')\n",
    "gpt_output = gpt_output.explode('gpt_output').reset_index(drop = True).drop_duplicates()\n",
    "manual_file = pd.read_csv('data/train_drug_label_text_manual_ades.csv',\n",
    "                          usecols = ['drug_name', 'reaction_string', 'meddra_pt', 'section_name',\n",
    "                                     'discontinuous_term', 'negated_term', 'meddra_exact_term']).drop_duplicates()\n",
    "gpt_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_embeds = model.encode(gpt_output['gpt_output'].tolist())\n",
    "gpt_output['embeds'] = list(gpt_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_embeds = model.encode(manual_file['reaction_string'].tolist())\n",
    "manual_file['embeds'] = list(man_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 0 11\n",
      "precision: 1.0\n",
      "recall: 0.875\n",
      "f1: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "for drug in manual_file.drug_name.unique():\n",
    "    sub_man = manual_file[manual_file.drug_name == drug]\n",
    "    sub_gpt = gpt_output[gpt_output.drug_name == drug]\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for row in sub_man.itertuples():\n",
    "        sims = [cos_sim(row.embeds, gpt_emb) for gpt_emb in sub_gpt.embeds]\n",
    "        # print(drug, row.reaction_string, sub_gpt.gpt_output.values[np.argmax(sims)], np.max(sims))\n",
    "        if np.max(sims) > THRESHOLD:\n",
    "            TP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "        \n",
    "    for row in sub_gpt.itertuples():\n",
    "        sims = [cos_sim(row.embeds, man_emb) for man_emb in sub_man.embeds]\n",
    "        if np.max(sims) < THRESHOLD:\n",
    "            FP += 1\n",
    "    print(TP, FP, FN)\n",
    "    print('precision:', TP / (TP + FP))\n",
    "    print('recall:', TP / (TP + FN))\n",
    "    print('f1:', 2 * (TP / (TP + FP)) * (TP / (TP + FN)) / ((TP / (TP + FP)) + (TP / (TP + FN))))\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "105,XEOMIN,all,46,41,41,0.0,5,1.0,0.8913043478260869,0.9425287356321839"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_cpus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
