{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from common_string import longest_common_substring_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(y_true, y_pred, flip_labels=False):\n",
    "    if flip_labels:\n",
    "        y_true = np.abs(np.array(y_true)-2)-1\n",
    "        y_pred = np.abs(np.array(y_pred)-2)-1\n",
    "    \n",
    "    tn, fp, fn, tp = map(float, confusion_matrix(y_true, y_pred).ravel())\n",
    "    specificity = tn/(tn+fp)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    fpr = fp/(fp+tn)\n",
    "    precision = tp/(tp+fp)\n",
    "    f1 = tp/(tp+0.5*(fp+fn))\n",
    "\n",
    "    return {\n",
    "        'flip_labels': flip_labels,\n",
    "        'TN': tn,\n",
    "        'FP': fp,\n",
    "        'FN': fn,\n",
    "        'TP': tp,\n",
    "        'specificity': specificity,\n",
    "        'sensitivity': sensitivity,\n",
    "        'fpr': fpr,\n",
    "        'precision': precision,\n",
    "        'F1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "umls_file = 'data/umls_meddra_en.csv'\n",
    "fh = open(umls_file)\n",
    "reader = csv.reader(fh)\n",
    "header = next(reader)\n",
    "\n",
    "meddra_terms = set()\n",
    "meddra_code2term = dict()\n",
    "for row in reader:\n",
    "    d = dict(zip(header, row))\n",
    "    meddra_terms.add(d['STR'].lower())\n",
    "    meddra_code2term[int(d['CODE'])] = d['STR'].lower()\n",
    "\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:00<00:00, 217.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99, 99)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the testing set\n",
    "folder = 'data/TAC2017/'\n",
    "\n",
    "test_labels = glob(folder+'gold_xml/*')\n",
    "\n",
    "drug2mentions = defaultdict(set)\n",
    "drug2reactions = defaultdict(set)\n",
    "\n",
    "for label in tqdm(test_labels):\n",
    "    drug_name = label.split('/')[-1].split('.')[0]\n",
    "    with open(label, 'r') as f:\n",
    "        soup = BeautifulSoup(f, 'xml')\n",
    "    \n",
    "    for mention in soup.find_all('Mention'):\n",
    "        if mention['type'] == 'AdverseReaction':\n",
    "          section_name = mention['section']\n",
    "          if section_name != 'S1':\n",
    "              continue\n",
    "            \n",
    "          mention_str = mention['str'].lower()\n",
    "          drug2mentions[drug_name].add(mention_str)\n",
    "    \n",
    "    for reaction in soup.find_all('Reaction'):\n",
    "        reaction_str = reaction['str']\n",
    "        drug2reactions[drug_name].add(reaction_str)\n",
    "\n",
    "len(drug2mentions), len(drug2reactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99, 6), 4743)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs_list = list()\n",
    "\n",
    "task3ref = list()\n",
    "\n",
    "for drug in drug2mentions.keys():\n",
    "\n",
    "    for rxn in (drug2mentions[drug] & drug2reactions[drug]):\n",
    "        task3ref.append([drug, rxn, 1])\n",
    "    \n",
    "    for rxn in (drug2mentions[drug] - drug2reactions[drug]):\n",
    "        task3ref.append([drug, rxn, 0])\n",
    "\n",
    "    setdiff = drug2mentions[drug]-drug2reactions[drug]\n",
    "    diff = len(drug2mentions[drug])-len(drug2reactions[drug])\n",
    "    setdiff_inmeddra = meddra_terms & drug2mentions[drug]\n",
    "    diffs_list.append([drug, len(drug2mentions[drug]), len(drug2reactions[drug]), diff, len(setdiff), len(setdiff_inmeddra)])\n",
    "\n",
    "diffs = pd.DataFrame(diffs_list, columns=['drug', 'nmentions', 'nreactions', 'diff', 'setdiff', 'nmeddraexact'])\n",
    "diffs.shape, len(task3ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_fn = 'results/task3/evaluation_metrics.json'\n",
    "metrics = None\n",
    "if os.path.exists(metrics_fn):\n",
    "    fh = open(metrics_fn)\n",
    "    metrics = json.load(fh)\n",
    "    fh.close()\n",
    "else:\n",
    "    metrics = dict()\n",
    "\n",
    "def save_metrics(metrics):\n",
    "    fh = open(metrics_fn, 'w')\n",
    "    json.dump(metrics, fh, indent=4)\n",
    "    fh.close()\n",
    "\n",
    "save_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OnSIDES BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4743/4743 [00:03<00:00, 1321.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4743, 2693, 4743)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load onsides from the best model and evaluated on the testing set\n",
    "pred_filename = 'data/task3/grouped-mean-final-bydrug-PMB_14-AR-125-all_222_TAC_25_2.5e-05_256_32.csv'\n",
    "ob_pred = pd.read_csv(pred_filename, index_col=0)\n",
    "events = list()\n",
    "\n",
    "for _, row in ob_pred.iterrows():\n",
    "    events.append(meddra_code2term[row['pt_meddra_id']])\n",
    "\n",
    "ob_pred.insert(3, \"event\", events)\n",
    "\n",
    "# from releases.json file in onsides\n",
    "threshold = 0.4633\n",
    "ob_predictions = list()\n",
    "\n",
    "# build prediction list\n",
    "for drug, rxn, label in tqdm(task3ref):\n",
    "    \n",
    "    if rxn.find('\"') != -1:\n",
    "        querystr = \"\"\"drug == '{}' & event == '{}' \"\"\".format(drug, rxn)\n",
    "    elif rxn.find(\"'\") != -1:\n",
    "        querystr = \"\"\"drug == \"{}\" & event == \"{}\" \"\"\".format(drug, rxn)\n",
    "    else:\n",
    "        querystr = \"drug == '{}' & event == '{}'\".format(drug, rxn)    \n",
    "    \n",
    "    p = ob_pred.query(querystr)\n",
    "\n",
    "    # NOTE: leniency is irrelevant here because OnSIDES-BERT only considers \n",
    "    # NOTE: terms that are exact matches from the label. So each term from \n",
    "    # NOTE: OnSIDES BERT must be present in the reference as mentioned.\n",
    "\n",
    "    if p.shape[0] == 0:\n",
    "        # not an exact match or not scored by OnsidesBERT\n",
    "        pred1 = 0.0\n",
    "    else:\n",
    "        pred1 = float(p['Pred1'])\n",
    "    \n",
    "    if pred1 >= threshold:\n",
    "        ob_predictions.append(1)\n",
    "    else:\n",
    "        ob_predictions.append(0)\n",
    "    \n",
    "len(ob_predictions), sum(ob_predictions), len(task3ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, labels = zip(*task3ref)\n",
    "em = eval_metrics(labels, ob_predictions, flip_labels=True)\n",
    "\n",
    "if not pred_filename in metrics:\n",
    "    metrics[pred_filename] = em\n",
    "\n",
    "save_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepCADRME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug_name</th>\n",
       "      <th>section_name</th>\n",
       "      <th>gpt_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMPAVIDO</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>nausea, vomiting, diarrhea, headache, decrease...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LIVALO</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>rhabdomyolysis, myoglobinuria, acute renal fai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XENAZINE</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>depression, suicidality, akathisia, restlessne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LINZESS</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>diarrhea, abdominal pain, flatulence, abdomina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OPSUMIT</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>embryo fetal toxicity, hepatotoxicity, decreas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>AUBAGIO</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>hepatotoxicity, bone marrow effects, immunosup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>POMALYST</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>fetal risk, venous, arterial thromboembolism, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>SURFAXIN</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>endotracheal tube reflux, pallor, endotracheal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>ARZERRA</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>infusion reactions, hepatitis b virus reactiva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>ESBRIET</td>\n",
       "      <td>adverse reactions</td>\n",
       "      <td>liver enzyme elevations, photosensitivity reac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    drug_name       section_name  \\\n",
       "0    IMPAVIDO  adverse reactions   \n",
       "3      LIVALO  adverse reactions   \n",
       "5    XENAZINE  adverse reactions   \n",
       "8     LINZESS  adverse reactions   \n",
       "11    OPSUMIT  adverse reactions   \n",
       "..        ...                ...   \n",
       "223   AUBAGIO  adverse reactions   \n",
       "226  POMALYST  adverse reactions   \n",
       "229  SURFAXIN  adverse reactions   \n",
       "231   ARZERRA  adverse reactions   \n",
       "234   ESBRIET  adverse reactions   \n",
       "\n",
       "                                            gpt_output  \n",
       "0    nausea, vomiting, diarrhea, headache, decrease...  \n",
       "3    rhabdomyolysis, myoglobinuria, acute renal fai...  \n",
       "5    depression, suicidality, akathisia, restlessne...  \n",
       "8    diarrhea, abdominal pain, flatulence, abdomina...  \n",
       "11   embryo fetal toxicity, hepatotoxicity, decreas...  \n",
       "..                                                 ...  \n",
       "223  hepatotoxicity, bone marrow effects, immunosup...  \n",
       "226  fetal risk, venous, arterial thromboembolism, ...  \n",
       "229  endotracheal tube reflux, pallor, endotracheal...  \n",
       "231  infusion reactions, hepatitis b virus reactiva...  \n",
       "234  liver enzyme elevations, photosensitivity reac...  \n",
       "\n",
       "[99 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_pred_filename = \"results/extract/deepcadrme_100_test.csv\"\n",
    "d_pred = pd.read_csv(d_pred_filename, index_col=0).query(\"section_name == 'adverse reactions'\")\n",
    "d_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4743/4743 [00:05<00:00, 821.12it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4743, 4560, 4743)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_predictions = list()\n",
    "\n",
    "for drug, rxn, label in tqdm(task3ref):\n",
    "\n",
    "    # extractions = str(d_pred.query(f\"drug_name == '{drug}'\")['gpt_output'])\n",
    "    extractions = list(d_pred.query(f\"drug_name == '{drug}'\")['gpt_output'].str.split(', '))[0]\n",
    "\n",
    "    # strict\n",
    "    # if rxn in extractions:\n",
    "    # lenient\n",
    "    if any([longest_common_substring_percentage(rxn, x) > 0.8 for x in extractions]):\n",
    "        d_predictions.append(1)\n",
    "    else:\n",
    "        d_predictions.append(0)\n",
    "\n",
    "len(d_predictions), sum(d_predictions), len(task3ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, labels = zip(*task3ref)\n",
    "em = eval_metrics(labels, d_predictions, flip_labels=True)\n",
    "\n",
    "if not d_pred_filename in metrics:\n",
    "    metrics[d_pred_filename] = em\n",
    "\n",
    "save_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onsides LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:07<00:21,  3.65s/it]"
     ]
    }
   ],
   "source": [
    "test_runs = [f for f in os.listdir('results/extract') if f.find('_test_') != -1]\n",
    "\n",
    "for runfile in tqdm(test_runs):\n",
    "    ol_pred_fn = os.path.join('results', 'extract', runfile)\n",
    "    \n",
    "    if ol_pred_fn in metrics:\n",
    "        continue\n",
    "\n",
    "    ol_pred = pd.read_csv(ol_pred_fn, index_col=0).query(\"section_name == 'adverse reactions'\")\n",
    "    ol_predictions = list()\n",
    "\n",
    "    for drug, rxn, label in task3ref:\n",
    "\n",
    "        extractions = list(ol_pred.query(f\"drug_name == '{drug}'\")['gpt_output'].str.split(', '))[0]\n",
    "\n",
    "        # strict\n",
    "        # if rxn in extractions:\n",
    "        # lenient\n",
    "        if any([longest_common_substring_percentage(rxn, x) > 0.8 for x in extractions]):\n",
    "            ol_predictions.append(1)\n",
    "        else:\n",
    "            ol_predictions.append(0)\n",
    "\n",
    "    _, _, labels = zip(*task3ref)\n",
    "    em = eval_metrics(labels, ol_predictions, flip_labels=True)\n",
    "\n",
    "    if not ol_pred_fn in metrics:\n",
    "        metrics[ol_pred_fn] = em\n",
    "\n",
    "    save_metrics(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ol_pred_fn = \"results/extract/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_test_run0.csv\"\n",
    "# # ol_pred_fn = 'results/extract/OpenAI_gpt-4-1106-preview_only-positives-v0_pharmexpert-v0_temp0_test_run0.csv'\n",
    "# ol_pred_fn = \"results/extract/OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_test_run0.csv\"\n",
    "# ol_pred = pd.read_csv(ol_pred_fn, index_col=0).query(\"section_name == 'adverse reactions'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4743/4743 [00:03<00:00, 1207.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4743, 3642, 4743)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ol_predictions = list()\n",
    "\n",
    "# for drug, rxn, label in tqdm(task3ref):\n",
    "\n",
    "#     extractions = list(ol_pred.query(f\"drug_name == '{drug}'\")['gpt_output'].str.split(', '))[0]\n",
    "\n",
    "#     # strict\n",
    "#     # if rxn in extractions:\n",
    "#     # lenient\n",
    "#     if any([longest_common_substring_percentage(rxn, x) > 0.8 for x in extractions]):\n",
    "#         ol_predictions.append(1)\n",
    "#     else:\n",
    "#         ol_predictions.append(0)\n",
    "\n",
    "# len(ol_predictions), sum(ol_predictions), len(task3ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, _, labels = zip(*task3ref)\n",
    "# em = eval_metrics(labels, ol_predictions, flip_labels=True)\n",
    "\n",
    "# if not ol_pred_fn in metrics:\n",
    "#     metrics[ol_pred_fn] = em\n",
    "\n",
    "# save_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug</th>\n",
       "      <th>event</th>\n",
       "      <th>label</th>\n",
       "      <th>OB</th>\n",
       "      <th>D</th>\n",
       "      <th>OL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMPAVIDO</td>\n",
       "      <td>flatulence</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMPAVIDO</td>\n",
       "      <td>arthritis</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMPAVIDO</td>\n",
       "      <td>platelet count &lt; 150,000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMPAVIDO</td>\n",
       "      <td>somnolence</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMPAVIDO</td>\n",
       "      <td>asthenia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4738</th>\n",
       "      <td>ESBRIET</td>\n",
       "      <td>insomnia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4739</th>\n",
       "      <td>ESBRIET</td>\n",
       "      <td>increases of alt</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4740</th>\n",
       "      <td>ESBRIET</td>\n",
       "      <td>gastro-esophageal reflux disease</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>ESBRIET</td>\n",
       "      <td>anorexia</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>ESBRIET</td>\n",
       "      <td>pruritus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4743 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          drug                             event  label  OB  D  OL\n",
       "0     IMPAVIDO                        flatulence      0   0  0   0\n",
       "1     IMPAVIDO                         arthritis      0   0  0   0\n",
       "2     IMPAVIDO          platelet count < 150,000      0   1  1   1\n",
       "3     IMPAVIDO                        somnolence      0   0  0   0\n",
       "4     IMPAVIDO                          asthenia      0   0  0   0\n",
       "...        ...                               ...    ...  .. ..  ..\n",
       "4738   ESBRIET                          insomnia      0   0  0   0\n",
       "4739   ESBRIET                  increases of alt      0   1  0   1\n",
       "4740   ESBRIET  gastro-esophageal reflux disease      0   1  1   0\n",
       "4741   ESBRIET                          anorexia      0   1  0   0\n",
       "4742   ESBRIET                          pruritus      0   0  0   0\n",
       "\n",
       "[4743 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile results\n",
    "d, e, l = zip(*task3ref)\n",
    "df_data = zip(d, e, l, ob_predictions, d_predictions, ol_predictions)\n",
    "\n",
    "predictions = pd.DataFrame(df_data, columns=[\"drug\", \"event\", \"label\", \"OB\", \"D\", \"OL\"])\n",
    "\n",
    "# flip all the labels\n",
    "flip_labels = True\n",
    "if flip_labels:\n",
    "    for colname in ('label', 'OB', 'D', 'OL'):\n",
    "        predictions[colname] = np.abs(predictions[colname]-2)-1\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D  Specificity: 0.962\n",
      "OB Specificity: 0.575\n",
      "OL Specificity: 0.774\n",
      "\n",
      "D  Recall/Sens: 0.065\n",
      "OB Recall/Sens: 0.857\n",
      "OL Recall/Sens: 0.597\n",
      "\n",
      "D  FPR        : 0.038\n",
      "OB FPR        : 0.425\n",
      "OL FPR        : 0.226\n",
      "\n",
      "D  Precision  : 0.027\n",
      "OB Precision  : 0.032\n",
      "OL Precision  : 0.042\n",
      "\n",
      "D  F1         : 0.038\n",
      "OB F1         : 0.062\n",
      "OL F1         : 0.078\n"
     ]
    }
   ],
   "source": [
    "for key in ('D', 'OB', 'OL'):\n",
    "    tn, fp, fn, tp = confusion_matrix(predictions['label'], predictions[key]).ravel()\n",
    "    print(f\"{key:2s} Specificity: {tn/(tn+fp):5.3f}\")\n",
    "\n",
    "print()\n",
    "for key in ('D', 'OB', 'OL'):\n",
    "    tn, fp, fn, tp = confusion_matrix(predictions['label'], predictions[key]).ravel()\n",
    "    print(f\"{key:2s} Recall/Sens: {tp/(tp+fn):5.3f}\")\n",
    "\n",
    "print()\n",
    "for key in ('D', 'OB', 'OL'):\n",
    "    tn, fp, fn, tp = confusion_matrix(predictions['label'], predictions[key]).ravel()\n",
    "    print(f\"{key:2s} FPR        : {fp/(fp+tn):5.3f}\")\n",
    "\n",
    "print()\n",
    "for key in ('D', 'OB', 'OL'):\n",
    "    tn, fp, fn, tp = confusion_matrix(predictions['label'], predictions[key]).ravel()\n",
    "    print(f\"{key:2s} Precision  : {tp/(tp+fp):5.3f}\")\n",
    "\n",
    "print()\n",
    "for key in ('D', 'OB', 'OL'):\n",
    "    tn, fp, fn, tp = confusion_matrix(predictions['label'], predictions[key]).ravel()\n",
    "    print(f\"{key:2s} F1         : {tp/(tp+0.5*(fp+fn)):5.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
