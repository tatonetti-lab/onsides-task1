{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706f8453-d366-4e8c-976c-90b59cf58197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "import concurrent\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from evaluation_functions import evaluate\n",
    "from openai_functions import extract_ade_terms\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db80a89-6744-4602-936e-c5457d547d20",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e95ad3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37930311-07c7-4762-abd1-cb249c5bd25d",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f5b7a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_dir = \"results/extract/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed8cc025-3af6-4bea-826b-962eb8b36f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "# drug_file = 'data/TAC2017/train_drug_label_text.csv'\n",
    "# manual_file = 'data/TAC2017/train_drug_label_text_manual_ades.csv'\n",
    "\n",
    "# test\n",
    "drug_file = 'data/TAC2017/train_drug_label_text.csv'\n",
    "manual_file = 'data/TAC2017/train_drug_label_text_manual_ades.csv'\n",
    "\n",
    "# my_max = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22518e4d-ec19-4a56-9914-cd969a50cbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs = pd.read_csv(drug_file)\n",
    "manual_ades = pd.read_csv(manual_file)\n",
    "set_type = drug_file.split('/')[2].split('_')[0] # assuming file follows format \"train_...\" or \"test....\"\n",
    "\n",
    "all_sections = drugs.query(\"section_name != 'all-concat'\").groupby('drug_name')['section_text'].apply(' '.join).reset_index()\n",
    "all_sections.insert(1, \"section_name\", [\"all-concat\" for _ in range(all_sections.shape[0])])\n",
    "drugs = pd.concat([drugs, all_sections])\n",
    "\n",
    "set_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c24736c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(340, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ae7da-2a0e-4755-ae4d-4bced5f7f5a2",
   "metadata": {},
   "source": [
    "## Run GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e618b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6f04e8a-be72-4ad8-abfe-7b5d60c03a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open('./config.json'))\n",
    "\n",
    "organization = \"\"\n",
    "\n",
    "api_source = 'OpenAI'\n",
    "\n",
    "api_key = config[api_source]['openai_api_key'] #constants.AZURE_OPENAI_KEY\n",
    "api_endpoint = config[api_source]['openai_api_endpoint'] \n",
    "\n",
    "gpt_model = config[api_source][\"gpt_model\"]\n",
    "# gpt_model = \"gpt-4-turbo-preview\"\n",
    "# gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "temperature = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4b1bbd7-3b6c-42f5-a2af-04391ea86537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nruns = 3\n",
    "\n",
    "system_options = {\n",
    "    \"no-system-prompt\": \"\",\n",
    "    \"pharmexpert-v0\": \"You are an expert in pharmacology.\",\n",
    "    \"pharmexpert-v1\": \"You are an expert in medical natural language processing, adverse drug reactions, pharmacology, and clinical trials.\"\n",
    "}\n",
    "\n",
    "prompt_options = {\n",
    "    \"fatal-prompt-v1\": \"\"\"\n",
    "Extract all adverse reactions and fatal outcomes as they appear, including all synonyms,\n",
    "mentioned in the following text provide them as a comma-separated list:\n",
    "'{}'\n",
    "\"\"\",\n",
    "    \"fatal-prompt-v2\": \"\"\"\n",
    "Extract all adverse reactions as they appear, including all synonyms.\n",
    "mentioned in the text and provide them as a comma-separated list.\n",
    "If a fatal event is listed add 'death' to the list.\n",
    "The text is :'{}' \n",
    "\"\"\",\n",
    "    \"fatal-prompt-v3\": \"\"\"\n",
    "Extract all adverse reactions as they appear, including all synonyms.\n",
    "mentioned in the text and provide them as a comma-separated list. If a\n",
    "negated adverse reaction appears extract it and include a <negated> tag.\n",
    "If a fatal event is listed add 'death' to the list.\n",
    "The text is :'{}'\n",
    "\"\"\",\n",
    "    \"only-positives-v0\": \"\"\"\n",
    "Extract all adverse events as they appear, including all synonyms mentioned in the text\n",
    "and provide them as a comma separated list. Only include adverse events that\n",
    "have evidence of a causal relationship to the drug exposure. If a fatal event\n",
    "is listed add 'death' to to the list.\n",
    "The text is :'{}'\n",
    "\"\"\",\n",
    "    \"gpt-written-prompt\":\"\"\"\n",
    "Given the structured product label below, extract information on adverse drug reactions and provide the exact mentions of reactions\n",
    "in a comma-separated format. Consider sentence-form expressions, reactions in tables, negated reactions, discontinuous mentions,\n",
    "hypothetical scenarios, and potentially fatal occurrences. Ensure the extraction is comprehensive, covering both explicit and \n",
    "implicit references to adverse reactions.\n",
    "The text from the structured product label is:\n",
    "'{}'\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "system_name = \"pharmexpert-v0\"\n",
    "system_content = system_options[system_name]\n",
    "\n",
    "prompt_name = \"gpt-written-prompt\"\n",
    "prompt = prompt_options[prompt_name]\n",
    "\n",
    "gpt_params = [f\"temp{temperature}\"]\n",
    "\n",
    "output_file_basename = '{}_{}_{}_{}_{}_{}'.format(api_source, gpt_model, prompt_name, system_name, '-'.join(gpt_params), set_type)\n",
    "output_file_basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "492d7e82-894f-4c0f-bbf1-4de819b94b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run0\n",
      "Loaded 0 rows from file since they were already run.\n",
      "There remains 340 rows to run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/340 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 340/340 [08:38<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run0, time elapsed: 518.9125990867615s.\n",
      "OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run1\n",
      "Loaded 0 rows from file since they were already run.\n",
      "There remains 340 rows to run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 340/340 [08:23<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run1, time elapsed: 503.4470179080963s.\n",
      "OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run2\n",
      "Loaded 0 rows from file since they were already run.\n",
      "There remains 340 rows to run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 340/340 [08:22<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run2, time elapsed: 502.4956181049347s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# run GPT\n",
    "for i in range(nruns):\n",
    "    run_key = \"{}_run{}\".format(output_file_basename, i)\n",
    "    print(run_key)\n",
    "    if run_key in outputs:\n",
    "        print(f\"Run {run_key} already started will pick up from where it was left off.\")\n",
    "    elif os.path.exists('{}/{}.csv'.format(extract_dir, run_key)):\n",
    "        gpt_output = pd.read_csv('{}/{}.csv'.format(extract_dir, run_key))\n",
    "        outputs[run_key] = gpt_output\n",
    "        print(f\"Run {run_key} started, loading from disk and pick up from where it was left off.\")\n",
    "    \n",
    "    start = time.time()\n",
    "    results = list()\n",
    "    rows_to_run = list()\n",
    "    for _, row in drugs.iterrows():\n",
    "        name, section = row['drug_name'], row['section_name']\n",
    "\n",
    "        if run_key in outputs:\n",
    "            prev_run_results = outputs[run_key].query(f\"drug_name == '{name}'\").query(f\"section_name == '{section}'\")\n",
    "            if prev_run_results.shape[0]==1:\n",
    "                results.append([name, section, prev_run_results.gpt_output.values[0]])\n",
    "            else:\n",
    "                rows_to_run.append(row)\n",
    "        else:\n",
    "            rows_to_run.append(row)\n",
    "        \n",
    "    print(f\"Loaded {len(results)} rows from file since they were already run.\")\n",
    "    print(f\"There remains {len(rows_to_run)} rows to run.\")\n",
    "\n",
    "    def run_iteration(row):\n",
    "        name, section = row['drug_name'], row['section_name']\n",
    "        text = row['section_text']\n",
    "        try:\n",
    "            gpt_out = extract_ade_terms(api_source, config, gpt_model, system_content, prompt, text, temperature)\n",
    "            return [name, section, gpt_out]\n",
    "        except Exception as err:\n",
    "            print(f\"Encountered an exception for row: {name} {section}. Error message below:\")\n",
    "            print(err)\n",
    "            return None\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as exec:\n",
    "        results.extend(list(tqdm(\n",
    "            exec.map(run_iteration, rows_to_run), \n",
    "            total=len(rows_to_run)\n",
    "        )))\n",
    "            \n",
    "    gpt_output = pd.DataFrame(\n",
    "        [r for r in results if r is not None],\n",
    "        columns=['drug_name', 'section_name', 'gpt_output']\n",
    "    )\n",
    "    end = time.time()\n",
    "    \n",
    "    if gpt_output.shape[0] > 0:\n",
    "        outputs[run_key] = gpt_output\n",
    "        gpt_output.to_csv('{}/{}.csv'.format(extract_dir, run_key))\n",
    "    \n",
    "    print(f\"Run: {run_key}, time elapsed: {end-start}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7986085b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3e1252e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run0\n",
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run1\n",
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run2\n",
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run0\n",
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run1\n",
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run2\n",
      "OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run0\n",
      "OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run1\n",
      "OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run2\n"
     ]
    }
   ],
   "source": [
    "for run_key in sorted(outputs.keys()):\n",
    "    print(run_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "787d7804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running strict evaluation and saving results to disk.\n",
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run0\n",
      "saving results to results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run0_strict_granular.csv and results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run0_strict_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/101 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:05<00:00, 18.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run1\n",
      "saving results to results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run1_strict_granular.csv and results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run1_strict_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:05<00:00, 18.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run2\n",
      "saving results to results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run2_strict_granular.csv and results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run2_strict_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:05<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run0\n",
      "saving results to results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run0_strict_granular.csv and results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run0_strict_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:05<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run1\n",
      "saving results to results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run1_strict_granular.csv and results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run1_strict_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:05<00:00, 17.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run2\n",
      "saving results to results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run2_strict_granular.csv and results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run2_strict_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:05<00:00, 17.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run0\n",
      "saving results to results/evals/OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run0_strict_granular.csv and results/evals/OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run0_strict_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:05<00:00, 17.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run1\n",
      "saving results to results/evals/OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run1_strict_granular.csv and results/evals/OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run1_strict_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:05<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run2\n",
      "saving results to results/evals/OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run2_strict_granular.csv and results/evals/OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run2_strict_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:05<00:00, 17.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running lenient evaluation and saving results to disk.\n",
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run0\n",
      "saving results to results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run0_lenient_granular.csv and results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run0_lenient_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:35<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run1\n",
      "saving results to results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run1_lenient_granular.csv and results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run1_lenient_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:35<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run2\n",
      "saving results to results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run2_lenient_granular.csv and results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run2_lenient_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:36<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run0\n",
      "saving results to results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run0_lenient_granular.csv and results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run0_lenient_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:37<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run1\n",
      "saving results to results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run1_lenient_granular.csv and results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run1_lenient_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:34<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run2\n",
      "saving results to results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run2_lenient_granular.csv and results/evals/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v1_temp0_train_run2_lenient_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:35<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run0\n",
      "saving results to results/evals/OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run0_lenient_granular.csv and results/evals/OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run0_lenient_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:35<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run1\n",
      "saving results to results/evals/OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run1_lenient_granular.csv and results/evals/OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run1_lenient_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:34<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run2\n",
      "saving results to results/evals/OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run2_lenient_granular.csv and results/evals/OpenAI_gpt-4-1106-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run2_lenient_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:36<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluate(outputs, manual_ades, 'strict')\n",
    "evaluate(outputs, manual_ades, 'lenient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d376cd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uog2000/miniconda3/envs/llm_cpus/lib/python3.11/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/uog2000/miniconda3/envs/llm_cpus/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/uog2000/miniconda3/envs/llm_cpus/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
     ]
    }
   ],
   "source": [
    "# if using embeddings -- run this once:\n",
    "# get embeddings for manual annotation --- this part is slow -- but should take <5 min\n",
    "embed_model_name = 'llmrails/ember-v1'\n",
    "embed_model = SentenceTransformer(embed_model_name)\n",
    "man_embeds = embed_model.encode(manual_ades['reaction_string'].tolist())\n",
    "manual_ades['embeds'] = list(man_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11058bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running embed evaluation and saving results to disk.\n",
      "OpenAI_gpt-4-turbo-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run0\n",
      "saving results to results/OpenAI_gpt-4-turbo-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run0_ember-v1_granular.csv and results/OpenAI_gpt-4-turbo-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run0_ember-v1_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 101/101 [05:32<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-turbo-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run1\n",
      "saving results to results/OpenAI_gpt-4-turbo-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run1_ember-v1_granular.csv and results/OpenAI_gpt-4-turbo-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run1_ember-v1_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 101/101 [05:20<00:00,  3.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-turbo-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run2\n",
      "saving results to results/OpenAI_gpt-4-turbo-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run2_ember-v1_granular.csv and results/OpenAI_gpt-4-turbo-preview_gpt-written-prompt_pharmexpert-v0_temp0_train_run2_ember-v1_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 101/101 [06:39<00:00,  3.96s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluate(outputs, manual_ades, 'embed', embed_model=embed_model, embed_model_name=embed_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e113a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
