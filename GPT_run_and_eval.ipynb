{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "706f8453-d366-4e8c-976c-90b59cf58197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "import constants\n",
    "import csv\n",
    "import numpy as np\n",
    "import concurrent\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db80a89-6744-4602-936e-c5457d547d20",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8759fb31-5cee-46e8-a65f-36bf14b08730",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98fa878b-b40a-4895-808e-9574b7d004c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for running GPT\n",
    "def extract_ade_terms(gpt_model, prompt, text, openai_api):\n",
    "  client = OpenAI(api_key=openai_api,)\n",
    "  chat_completion = client.chat.completions.create(\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": \"You are an expert in pharmacology.\"},\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": prompt.format(text)\n",
    "          }\n",
    "      ],\n",
    "      model=gpt_model,\n",
    "  )\n",
    "  term = chat_completion.choices[0].message.content\n",
    "  return term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bdb19ac-282a-47f0-8538-a0af057570cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(manual_ades, gpt_output, limit = 1000):\n",
    "    drugs = gpt_output['drug_name'].unique()\n",
    "    drugs_set = set()\n",
    "    results = []\n",
    "    for drug in tqdm(drugs):\n",
    "        drugs_set.add(drug)\n",
    "        if len(drugs_set) > limit:\n",
    "            break\n",
    "        \n",
    "        drug_df = manual_ades.query(\"(drug_name == '{}') & (section_name == 'adverse reactions')\".format(drug))\n",
    "        manual = set(drug_df['reaction_string'].to_list())\n",
    "        gpt_drug = (gpt_output[\n",
    "            (gpt_output['drug_name'] == drug)\n",
    "            &\n",
    "            (gpt_output['section_name'] == \"adverse reactions\")\n",
    "            ][\"gpt_output\"].astype(str)\n",
    "            .str.lower()\n",
    "            .str.replace('\\n-', ', ')\n",
    "            .str.split(\",\").tolist())\n",
    "    \n",
    "        try:\n",
    "            gpt_drug = [x.strip() for x in gpt_drug[0]]\n",
    "            gpt_drug = set(gpt_drug)\n",
    "        except:\n",
    "            results.append([drug, len(manual), len(gpt_drug), np.nan, np.nan,\n",
    "                             np.nan, np.nan, np.nan, np.nan])\n",
    "            continue\n",
    "\n",
    "        TP = len(manual.intersection(gpt_drug))\n",
    "        FP = len(gpt_drug.difference(manual))\n",
    "        FN = len(manual.difference(gpt_drug))\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        if precision != 0 and recall != 0:\n",
    "            f1 = (2 * precision * recall)/(precision + recall)# 2*TP/(2*TP+FP+FN)\n",
    "        else:\n",
    "            f1 = np.NAN\n",
    "\n",
    "        results.append([drug, len(manual), len(gpt_drug), TP, FP, FN, precision, recall, f1])\n",
    "    results = pd.DataFrame(results, columns=['drug_name', 'n_manual', 'n_gpt', 'tp', 'fp', 'fn', 'precision', 'recall', 'f1'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd0bffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_subtype(manual_ades, gpt_output, drug, subtype = 'all'):\n",
    "    '''\n",
    "    For a given drug, evaluate the performance of GPT on a given subtype of ADEs. \n",
    "    '''\n",
    "    \n",
    "    drug_df = manual_ades.query(\"(drug_name == '{}') & (section_name == 'adverse reactions')\".format(drug))\n",
    "    if subtype == 'exact-meddra': drug_df = drug_df[drug_df.meddra_exact_term == 1]\n",
    "    if subtype == 'non-meddra': drug_df = drug_df[drug_df.meddra_exact_term == 0]\n",
    "    if subtype == 'negated': drug_df = drug_df[drug_df.negated_term == 1]\n",
    "    if subtype == 'discontinuous': drug_df = drug_df[drug_df.discontinuous_term == 1]\n",
    "\n",
    "    manual = set(drug_df['reaction_string'].to_list())\n",
    "    gpt_drug = (gpt_output[\n",
    "        (gpt_output['drug_name'] == drug)\n",
    "        &\n",
    "        (gpt_output['section_name'] == \"adverse reactions\")\n",
    "        ][\"gpt_output\"].astype(str)\n",
    "        .str.lower()\n",
    "        .str.replace('\\n-', ', ')\n",
    "        .str.split(\",\").tolist())\n",
    "\n",
    "    try:\n",
    "        gpt_drug = [x.strip() for x in gpt_drug[0]]\n",
    "        gpt_drug = set(gpt_drug)\n",
    "    except:\n",
    "        return [drug, subtype, len(manual), len(gpt_drug), np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "    \n",
    "    #overall\n",
    "    TP = len(manual.intersection(gpt_drug))\n",
    "    FP = len(gpt_drug.difference(manual))\n",
    "    FN = len(manual.difference(gpt_drug))\n",
    "    if TP == 0 and FP == 0:\n",
    "        precision = np.NAN\n",
    "    else:\n",
    "        precision = TP/(TP+FP)\n",
    "    if TP == 0 and FN == 0:\n",
    "        recall = np.NAN\n",
    "    else:\n",
    "        recall = TP/(TP+FN)\n",
    "    if precision != 0 and recall != 0:\n",
    "        f1 = (2 * precision * recall)/(precision + recall)# 2*TP/(2*TP+FP+FN)\n",
    "    else:\n",
    "        f1 = np.NAN\n",
    "    \n",
    "    return [drug, subtype, len(manual), len(gpt_drug), TP, FP, FN, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d669d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_granular(manual_ades, gpt_output, limit = 1000):\n",
    "    drugs = gpt_output['drug_name'].unique()\n",
    "    drugs_set = set()\n",
    "    results = []\n",
    "    for drug in tqdm(drugs):\n",
    "        drugs_set.add(drug)\n",
    "        if len(drugs_set) > limit:\n",
    "            break\n",
    "        \n",
    "        results.append(evaluation_subtype(manual_ades, gpt_output, drug, subtype = 'all'))\n",
    "        results.append(evaluation_subtype(manual_ades, gpt_output, drug, subtype = 'exact-meddra'))\n",
    "        results.append(evaluation_subtype(manual_ades, gpt_output, drug, subtype = 'non-meddra'))\n",
    "        results.append(evaluation_subtype(manual_ades, gpt_output, drug, subtype = 'negated'))\n",
    "        results.append(evaluation_subtype(manual_ades, gpt_output, drug, subtype = 'discontinuous'))\n",
    "\n",
    "    results = pd.DataFrame(results, columns=['drug_name', 'ade_type', 'n_manual', 'n_gpt', 'tp', 'fp', 'fn', 'precision', 'recall', 'f1'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6f04e8a-be72-4ad8-abfe-7b5d60c03a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.organization = \"\"\n",
    "openai.api_key = \"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\" #constants.AZURE_OPENAI_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37930311-07c7-4762-abd1-cb249c5bd25d",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed8cc025-3af6-4bea-826b-962eb8b36f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_file = 'test_drug_label_text.csv'\n",
    "manual_file = 'test_drug_label_text_manual_ades.csv'\n",
    "my_max = 10000\n",
    "gpt_model = 'gpt-4-1106-preview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4b1bbd7-3b6c-42f5-a2af-04391ea86537",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_name = 'fatal-prompt-v2'\n",
    "prompt = \"\"\"\n",
    "Extract all adverse reactions as they appear, including all synonyms.\n",
    "mentioned in the text and provide them as a comma-separated list.\n",
    "If a fatal event is listed add 'death' to the list.\n",
    "The text is :'{}' \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ae7da-2a0e-4755-ae4d-4bced5f7f5a2",
   "metadata": {},
   "source": [
    "## Run GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22518e4d-ec19-4a56-9914-cd969a50cbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4-1106-preview_fatal-prompt-v2_test.csv\n"
     ]
    }
   ],
   "source": [
    "drugs = pd.read_csv(drug_file)\n",
    "manual_ades = pd.read_csv(manual_file)\n",
    "set_type = drug_file.split('_')[0] # assuming file follows format \"train_...\" or \"test....\"\n",
    "print('{}_{}_{}.csv'.format(gpt_model, prompt_name, set_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdb9c192-ba44-4135-8d3c-7b6ba6644563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is a max\n",
    "new_rows = list()\n",
    "unique_drugs = set()\n",
    "for i, row in drugs.iterrows():\n",
    "    unique_drugs.add(row[\"drug_name\"])\n",
    "    if len(unique_drugs) > my_max: \n",
    "        break\n",
    "    if row['section_name'] != 'adverse reactions':\n",
    "        continue\n",
    "\n",
    "    new_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "492d7e82-894f-4c0f-bbf1-4de819b94b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [02:39<00:00,  1.62s/it]\n"
     ]
    }
   ],
   "source": [
    "# run GPT    \n",
    "start = time.time()\n",
    "def run_iteration(row):\n",
    "    name, section = row['drug_name'], row['section_name']\n",
    "    text = row['section_text']\n",
    "    try:\n",
    "        gpt_out = extract_ade_terms(gpt_model, prompt, text, openai.api_key)\n",
    "        return [name, section, gpt_out]\n",
    "    except:\n",
    "        return None\n",
    "        \n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as exec:\n",
    "    results = list(tqdm(\n",
    "\t\texec.map(run_iteration, new_rows), \n",
    "\t\ttotal=len(new_rows)\n",
    "\t))\n",
    "\n",
    "gpt_output = pd.DataFrame(\n",
    "    [r for r in results if r is not None],\n",
    "    columns=['drug_name', 'section_name', 'gpt_output']\n",
    ")\n",
    "gpt_output.to_csv('{}_{}_{}.csv'.format(gpt_model, prompt_name, set_type))\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ded0abf-414e-49b9-aeaf-d3e6854d9d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160.09201788902283\n"
     ]
    }
   ],
   "source": [
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f2a47f6-5f13-4058-b22d-b58327818ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:00<00:00, 594.45it/s]\n"
     ]
    }
   ],
   "source": [
    "results = evaluation(manual_ades, gpt_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1913b5d8-28c5-4fd7-99c5-d0b104cbafa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: fatal-prompt-v2\n",
      "precision: 0.8749677751997937\n",
      "recall: 0.7273896270895842\n",
      "f1: 0.7943826799297835\n"
     ]
    }
   ],
   "source": [
    "[tp_total, fp_total, fn_total] =  results[['tp', 'fp', 'fn']].sum()\n",
    "precision = tp_total/(tp_total+fp_total)\n",
    "recall =  tp_total/(tp_total+fn_total)\n",
    "f1 = (2 * precision * recall)/(precision + recall) # 2*tp_total/(2*tp_total+fp_total+fn_total) \n",
    "print(\"prompt: {}\".format(prompt_name))\n",
    "print(\"precision: {}\\nrecall: {}\\nf1: {}\".format(precision, recall, f1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7cf4f90-c471-4294-95e1-304dba7a32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, data, prompt, precision, recall, f1\n",
    "with open('gpt_model_results.csv', 'a') as file:\n",
    "    file.write('{}, {}, {}, {}, {}, {}\\n'.format(gpt_model, set_type, prompt_name, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91e19fd",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9d3d2ea-acbc-49bb-a7e4-348ad0ab472e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:00<00:00, 137.81it/s]\n"
     ]
    }
   ],
   "source": [
    "results_granular = evaluation_granular(manual_ades, gpt_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a63a404e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n_/hh_by1z91yd4l5wmkyclq4r00000gn/T/ipykernel_24408/3749198768.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  overall_results = results_granular.groupby('ade_type')['tp', 'fp', 'fn'].apply(sum)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ade_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>3394</td>\n",
       "      <td>485</td>\n",
       "      <td>1272</td>\n",
       "      <td>0.874968</td>\n",
       "      <td>0.727390</td>\n",
       "      <td>0.794383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discontinuous</th>\n",
       "      <td>20</td>\n",
       "      <td>3859</td>\n",
       "      <td>329</td>\n",
       "      <td>0.005156</td>\n",
       "      <td>0.057307</td>\n",
       "      <td>0.009461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact-meddra</th>\n",
       "      <td>3003</td>\n",
       "      <td>876</td>\n",
       "      <td>539</td>\n",
       "      <td>0.774169</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.809325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negated</th>\n",
       "      <td>21</td>\n",
       "      <td>3858</td>\n",
       "      <td>28</td>\n",
       "      <td>0.005414</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.010692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-meddra</th>\n",
       "      <td>391</td>\n",
       "      <td>3488</td>\n",
       "      <td>733</td>\n",
       "      <td>0.100799</td>\n",
       "      <td>0.347865</td>\n",
       "      <td>0.156306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tp    fp    fn  precision    recall        f1\n",
       "ade_type                                                      \n",
       "all            3394   485  1272   0.874968  0.727390  0.794383\n",
       "discontinuous    20  3859   329   0.005156  0.057307  0.009461\n",
       "exact-meddra   3003   876   539   0.774169  0.847826  0.809325\n",
       "negated          21  3858    28   0.005414  0.428571  0.010692\n",
       "non-meddra      391  3488   733   0.100799  0.347865  0.156306"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_results = results_granular.groupby('ade_type')['tp', 'fp', 'fn'].apply(sum)\n",
    "overall_results['precision'] = overall_results['tp']/(overall_results['tp']+overall_results['fp'])\n",
    "overall_results['recall'] = overall_results['tp']/(overall_results['tp']+overall_results['fn'])\n",
    "overall_results['f1'] = (2 * overall_results['precision'] * overall_results['recall'])/(overall_results['precision'] + overall_results['recall']) # 2*tp_total/(2*tp_total+fp_total+fn_total)\n",
    "overall_results.to_csv('{}_{}_{}_granular.csv'.format(gpt_model, prompt_name, set_type))\n",
    "overall_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477e88a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_granular.groupby(['ade_type'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
