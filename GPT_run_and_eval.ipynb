{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706f8453-d366-4e8c-976c-90b59cf58197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "import concurrent\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from evaluation_functions import evaluate\n",
    "from openai_functions import extract_ade_terms\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db80a89-6744-4602-936e-c5457d547d20",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37930311-07c7-4762-abd1-cb249c5bd25d",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed8cc025-3af6-4bea-826b-962eb8b36f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "drug_file = 'data/train_drug_label_text.csv'\n",
    "manual_file = 'data/train_drug_label_text_manual_ades.csv'\n",
    "\n",
    "# test\n",
    "# drug_file = 'data/test_drug_label_text.csv'\n",
    "# manual_file = 'data/test_drug_label_text_manual_ades.csv'\n",
    "\n",
    "# my_max = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22518e4d-ec19-4a56-9914-cd969a50cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = pd.read_csv(drug_file)\n",
    "manual_ades = pd.read_csv(manual_file)\n",
    "set_type = drug_file.split('/')[1].split('_')[0] # assuming file follows format \"train_...\" or \"test....\"\n",
    "\n",
    "all_sections = drugs.query(\"section_name != 'all-concat'\").groupby('drug_name')['section_text'].apply(' '.join).reset_index()\n",
    "all_sections.insert(1, \"section_name\", [\"all-concat\" for _ in range(all_sections.shape[0])])\n",
    "drugs = pd.concat([drugs, all_sections])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c24736c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(340, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ae7da-2a0e-4755-ae4d-4bced5f7f5a2",
   "metadata": {},
   "source": [
    "## Run GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e618b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6f04e8a-be72-4ad8-abfe-7b5d60c03a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open('./config.json'))\n",
    "\n",
    "organization = \"\"\n",
    "\n",
    "api_source = 'OpenAI'\n",
    "\n",
    "api_key = config[api_source]['openai_api_key'] #constants.AZURE_OPENAI_KEY\n",
    "api_endpoint = config[api_source]['openai_api_endpoint'] \n",
    "\n",
    "gpt_model = config[api_source][\"gpt_model\"]\n",
    "# gpt_model = \"gpt-4-turbo-preview\"\n",
    "gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "temperature = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4b1bbd7-3b6c-42f5-a2af-04391ea86537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v1_temp0_train'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nruns = 3\n",
    "\n",
    "system_options = {\n",
    "    \"no-system-prompt\": \"\",\n",
    "    \"pharmexpert-v0\": \"You are an expert in pharmacology.\",\n",
    "    \"pharmexpert-v1\": \"You are an expert in medical natural language processing, adverse drug reactions, pharmacology, and clinical trials.\"\n",
    "}\n",
    "\n",
    "prompt_options = {\n",
    "    \"fatal-prompt-v2\": \"\"\"\n",
    "Extract all adverse reactions as they appear, including all synonyms.\n",
    "mentioned in the text and provide them as a comma-separated list.\n",
    "If a fatal event is listed add 'death' to the list.\n",
    "The text is :'{}' \n",
    "\"\"\",\n",
    "    \"fatal-prompt-v3\": \"\"\"\n",
    "Extract all adverse reactions as they appear, including all synonyms.\n",
    "mentioned in the text and provide them as a comma-separated list. If a\n",
    "negated adverse reaction appears extract it and include a <negated> tag.\n",
    "If a fatal event is listed add 'death' to the list.\n",
    "The text is :'{}' \n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "system_name = \"pharmexpert-v1\"\n",
    "system_content = system_options[system_name]\n",
    "\n",
    "prompt_name = \"fatal-prompt-v2\"\n",
    "prompt = prompt_options[prompt_name]\n",
    "\n",
    "gpt_params = [f\"temp{temperature}\"]\n",
    "\n",
    "output_file_basename = '{}_{}_{}_{}_{}_{}'.format(api_source, gpt_model, prompt_name, system_name, '-'.join(gpt_params), set_type)\n",
    "output_file_basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "492d7e82-894f-4c0f-bbf1-4de819b94b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v1_temp0_train_run0\n",
      "Run OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v1_temp0_train_run0 started, loading from disk and pick up from where it was left off.\n",
      "Loaded 340 rows from file since they were already run.\n",
      "There remains 0 rows to run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v1_temp0_train_run0, time elapsed: 0.7512528896331787s.\n",
      "OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v1_temp0_train_run1\n",
      "Run OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v1_temp0_train_run1 started, loading from disk and pick up from where it was left off.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 340 rows from file since they were already run.\n",
      "There remains 0 rows to run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v1_temp0_train_run1, time elapsed: 0.710963249206543s.\n",
      "OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v1_temp0_train_run2\n",
      "Run OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v1_temp0_train_run2 started, loading from disk and pick up from where it was left off.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 340 rows from file since they were already run.\n",
      "There remains 0 rows to run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v1_temp0_train_run2, time elapsed: 0.6979200839996338s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# run GPT\n",
    "for i in range(nruns):\n",
    "    run_key = \"{}_run{}\".format(output_file_basename, i)\n",
    "    print(run_key)\n",
    "    if run_key in outputs:\n",
    "        print(f\"Run {run_key} already started will pick up from where it was left off.\")\n",
    "    elif os.path.exists('results/{}.csv'.format(run_key)):\n",
    "        gpt_output = pd.read_csv('results/{}.csv'.format(run_key))\n",
    "        outputs[run_key] = gpt_output\n",
    "        print(f\"Run {run_key} started, loading from disk and pick up from where it was left off.\")\n",
    "    \n",
    "    start = time.time()\n",
    "    results = list()\n",
    "    rows_to_run = list()\n",
    "    for _, row in drugs.iterrows():\n",
    "        name, section = row['drug_name'], row['section_name']\n",
    "\n",
    "        if run_key in outputs:\n",
    "            prev_run_results = outputs[run_key].query(f\"drug_name == '{name}'\").query(f\"section_name == '{section}'\")\n",
    "            if prev_run_results.shape[0]==1:\n",
    "                results.append([name, section, prev_run_results.gpt_output.values[0]])\n",
    "            else:\n",
    "                rows_to_run.append(row)\n",
    "        else:\n",
    "            rows_to_run.append(row)\n",
    "        \n",
    "    print(f\"Loaded {len(results)} rows from file since they were already run.\")\n",
    "    print(f\"There remains {len(rows_to_run)} rows to run.\")\n",
    "\n",
    "    def run_iteration(row):\n",
    "        name, section = row['drug_name'], row['section_name']\n",
    "        text = row['section_text']\n",
    "        try:\n",
    "            gpt_out = extract_ade_terms(api_source, config, gpt_model, system_content, prompt, text, temperature)\n",
    "            return [name, section, gpt_out]\n",
    "        except Exception as err:\n",
    "            print(f\"Encountered an exception for row: {name} {section}. Error message below:\")\n",
    "            print(err)\n",
    "            return None\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as exec:\n",
    "        results.extend(list(tqdm(\n",
    "            exec.map(run_iteration, rows_to_run), \n",
    "            total=len(rows_to_run)\n",
    "        )))\n",
    "            \n",
    "    gpt_output = pd.DataFrame(\n",
    "        [r for r in results if r is not None],\n",
    "        columns=['drug_name', 'section_name', 'gpt_output']\n",
    "    )\n",
    "    end = time.time()\n",
    "    \n",
    "    if gpt_output.shape[0] > 0:\n",
    "        outputs[run_key] = gpt_output\n",
    "        gpt_output.to_csv('results/{}.csv'.format(run_key))\n",
    "    \n",
    "    print(f\"Run: {run_key}, time elapsed: {end-start}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7986085b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3e1252e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v1_temp0_train_run0\n",
      "OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v1_temp0_train_run1\n",
      "OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v1_temp0_train_run2\n"
     ]
    }
   ],
   "source": [
    "for run_key in sorted(outputs.keys()):\n",
    "    print(run_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6c19d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = {'thrombocytopenia', 'anemia', 'death', 'acute renal failure', 'pulmonary toxicity', 'hepatic failure', 'nausea', 'infusion reactions', 'pulmonary hypertension', 'hepatic toxicity', 'decreased lymphocyte', 'dyspnea', 'tumor lysis syndrome', 'diarrhea', 'fatigue', 'pyrexia', 'edema peripheral', 'hypertension', 'decreased platelets', 'cardiac toxicities', 'hemolytic uremic syndrome', 'headache', 'venous thrombosis', 'thrombotic thrombocytopenic purpura', 'cough', 'posterior reversible encephalopathy syndrome'}\n",
    "man = {'cardiac failure congestive', 'died', 'thrombocytopenia', 'decreased total white blood cell count', 'leukopenia', 'dizziness', 'deafness', 'pulmonary toxicity', 'hepatic failure', 'pain in extremity', 'asthenia', 'cataract', 'rash', 'bronchopneumonia', 'hypophosphatemia', 'hypoalbuminemia', 'bronchitis', 'tumor lysis syndrome', 'diarrhea', 'decreased absolute neutrophil count', 'pyrexia', 'edema peripheral', 'musculoskeletal pain', 'muscle spasm', 'hypertension', 'ttp', 'cardiac toxicities', 'decreased phosphorus', 'myocardial ischemia', 'infection adverse events', 'anxiety', 'hypomagnesemia', 'decreased potassium', 'posterior reversible encephalopathy syndrome', 'insomnia', 'mortality', 'decreased appetite', 'hypoesthesia', 'dysphonia', 'viral infection', 'renal failure', 'hypercalcemia', 'febrile neutropenia', 'pain', 'lymphopenia', 'renal disorders', 'respiratory tract infection', 'infusion reactions', 'disease progression', 'congestive heart failure', 'pruritus', 'pneumonia', 'upper respiratory tract infection', 'hepatic toxicity', 'renal impairment', 'chills', 'muscle spasms', 'back pain', 'deaths', 'epistaxis', 'decreased sodium', 'hemolytic uremic syndrome', 'oropharyngeal pain', 'thrombotic thrombocytopenic purpura', 'dehydration', 'hyperkalemia', 'musculoskeletal chest pain', 'hypocalcemia', 'hyperuricemia', 'myalgia', 'dyspnea exertional', 'peripheral neuropathies nec', 'blurred vision', 'erythema', 'delirium', 'acute renal failure', 'renal failure acute', 'nausea', 'vomiting', 'nasopharyngitis', 'sepsis', 'hypotension', 'decreased lymphocyte', 'fatigue', 'fatal', 'hypertensive crisis', 'vision blurred', 'deep vein thrombosis', 'infusion site reaction', 'embolic and thrombotic events, venous', 'headache', 'cardiac failure', 'decreased lymphocytes', 'cardiac adverse events', 'hypertensive emergency', 'pulmonary edema', 'pulmonary embolism', 'myocardial infarction', 'decreased hemoglobin', 'influenza', 'paresthesia', 'hyperglycemia', 'neutropenia', 'abdominal pain upper', 'anemia', 'toothache', 'cardiac disorders', 'multi-organ failure', 'cardiac arrest', 'pres', 'hyperhidrosis', 'pulmonary hypertension', 'hypokalemia', 'dyspnea', 'dyspepsia', 'urinary tract infection', 'abdominal pain', 'decreased platelets', 'renal adverse events', 'venous thrombosis', 'muscular weakness', 'infections', 'cough', 'hus', 'arthralgia', 'multiple myeloma', 'constipation', 'hyponatremia'}\n",
    "len(man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "787d7804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running strict evaluation and saving results to disk.\n",
      "OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v1_temp0_train_run0\n",
      "saving results to results/OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v1_temp0_train_run0_strict_granular.csv and results/OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v1_temp0_train_run0_strict_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/101 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'recall' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate(outputs, manual_ades, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m evaluate(outputs, manual_ades, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlenient\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Columbia/Tatonetti_Lab/llm_onsides/onsides-task1/evaluation_functions.py:155\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(outputs, manual_ades, eval_method, embed_model_name, embed_model)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mprint\u001b[39m(run_key)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaving results to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgranular_save_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverall_save_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 155\u001b[0m results_granular \u001b[38;5;241m=\u001b[39m evaluation_granular(manual_ades, output, eval_method\u001b[38;5;241m=\u001b[39meval_method, embed_model \u001b[38;5;241m=\u001b[39m embed_model)\n\u001b[1;32m    156\u001b[0m overall_results \u001b[38;5;241m=\u001b[39m results_granular\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msection\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124made_type\u001b[39m\u001b[38;5;124m'\u001b[39m])[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfn\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39msum(min_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m    157\u001b[0m overall_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro_precision\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m overall_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m/\u001b[39m(overall_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39moverall_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfp\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/Columbia/Tatonetti_Lab/llm_onsides/onsides-task1/evaluation_functions.py:136\u001b[0m, in \u001b[0;36mevaluation_granular\u001b[0;34m(manual_ades, gpt_output, eval_method, embed_model)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m                 man_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(manual_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreaction_string\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list())\n\u001b[0;32m--> 136\u001b[0m             results\u001b[38;5;241m.\u001b[39mappend(evaluation_subtype(man_vals, gpt_vals, drug, eval_method\u001b[38;5;241m=\u001b[39meval_method, subtype\u001b[38;5;241m=\u001b[39msubtype))\n\u001b[1;32m    138\u001b[0m results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrug_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msection\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124made_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_manual\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_gpt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/Documents/Columbia/Tatonetti_Lab/llm_onsides/onsides-task1/evaluation_functions.py:102\u001b[0m, in \u001b[0;36mevaluation_subtype\u001b[0;34m(manual, gpt_vals, drug, section, subtype, eval_method)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m         f1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mNAN\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [drug, section, subtype, \u001b[38;5;28mlen\u001b[39m(manual), \u001b[38;5;28mlen\u001b[39m(gpt_vals), TP, FP, FN, precision, recall, f1]\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'recall' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "evaluate(outputs, manual_ades, 'strict')\n",
    "evaluate(outputs, manual_ades, 'lenient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d376cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using embeddings -- run this once:\n",
    "# get embeddings for manual annotation --- this part is slow -- but should take <5 min\n",
    "embed_model_name = 'llmrails/ember-v1'\n",
    "embed_model = SentenceTransformer(embed_model_name)\n",
    "man_embeds = embed_model.encode(manual_ades['reaction_string'].tolist())\n",
    "manual_ades['embeds'] = list(man_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11058bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(outputs, manual_ades, 'embed', embed_model=embed_model, embed_model_name=embed_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e113a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
