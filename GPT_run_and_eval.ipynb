{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706f8453-d366-4e8c-976c-90b59cf58197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "import openai\n",
    "import constants\n",
    "import csv\n",
    "import numpy as np\n",
    "import concurrent\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db80a89-6744-4602-936e-c5457d547d20",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8759fb31-5cee-46e8-a65f-36bf14b08730",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98fa878b-b40a-4895-808e-9574b7d004c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for running GPT\n",
    "def extract_ade_terms(api_source, api_endpoint, gpt_model, system_content, prompt, text, openai_api):\n",
    "  if api_source == 'OpenAI':\n",
    "    client = OpenAI(api_key=openai_api)\n",
    "  elif api_source == 'Azure':\n",
    "    client = AzureOpenAI(api_key=openai_api, api_version=\"2023-12-01-preview\", azure_endpoint=api_endpoint)\n",
    "  else:\n",
    "    raise Exception(f\"Unexpected API source requested: {api_source}\")\n",
    "  \n",
    "  chat_completion = client.chat.completions.create(\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": system_content},\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": prompt.format(text)\n",
    "          }\n",
    "      ],\n",
    "      model=gpt_model\n",
    "  )\n",
    "  term = chat_completion.choices[0].message.content\n",
    "  return term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0bffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_subtype(manual_ades, gpt_output, drug, subtype = 'all'):\n",
    "    '''\n",
    "    For a given drug, evaluate the performance of GPT on a given subtype of ADEs. \n",
    "    '''\n",
    "    \n",
    "    drug_df = manual_ades.query(\"(drug_name == '{}') & (section_name == 'adverse reactions')\".format(drug))\n",
    "    if subtype == 'exact-meddra': drug_df = drug_df[drug_df.meddra_exact_term == 1]\n",
    "    if subtype == 'non-meddra': drug_df = drug_df[drug_df.meddra_exact_term == 0]\n",
    "    if subtype == 'negated': drug_df = drug_df[drug_df.negated_term == 1]\n",
    "    if subtype == 'discontinuous': drug_df = drug_df[drug_df.discontinuous_term == 1]\n",
    "\n",
    "    manual = set(drug_df['reaction_string'].to_list())\n",
    "    gpt_drug = (gpt_output[\n",
    "        (gpt_output['drug_name'] == drug)\n",
    "        &\n",
    "        (gpt_output['section_name'] == \"adverse reactions\")\n",
    "        ][\"gpt_output\"].astype(str)\n",
    "        .str.lower()\n",
    "        .str.replace('\\n-', ', ')\n",
    "        .str.split(\",\").tolist())\n",
    "\n",
    "    try:\n",
    "        gpt_drug = [x.strip() for x in gpt_drug[0]]\n",
    "        gpt_drug = set(gpt_drug)\n",
    "    except:\n",
    "        return [drug, subtype, len(manual), len(gpt_drug), np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "    \n",
    "    #overall\n",
    "    TP = len(manual.intersection(gpt_drug))\n",
    "    FP = len(gpt_drug.difference(manual))\n",
    "    FN = len(manual.difference(gpt_drug))\n",
    "    if TP == 0 and FP == 0:\n",
    "        precision = np.NAN\n",
    "    else:\n",
    "        precision = TP/(TP+FP)\n",
    "    if TP == 0 and FN == 0:\n",
    "        recall = np.NAN\n",
    "    else:\n",
    "        recall = TP/(TP+FN)\n",
    "    if precision != 0 and recall != 0:\n",
    "        f1 = (2 * precision * recall)/(precision + recall)# 2*TP/(2*TP+FP+FN)\n",
    "    else:\n",
    "        f1 = np.NAN\n",
    "    \n",
    "    if subtype != 'all':\n",
    "        # these can't be computed for the subtypes\n",
    "        precision = np.nan\n",
    "        f1 = np.nan\n",
    "        FP = np.nan\n",
    "    \n",
    "    return [drug, subtype, len(manual), len(gpt_drug), TP, FP, FN, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8c6cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(manual_ades, gpt_output, limit = 1000):\n",
    "    drugs = gpt_output['drug_name'].unique()\n",
    "    drugs_set = set()\n",
    "    results = []\n",
    "    for drug in tqdm(drugs):\n",
    "\n",
    "        results.append(evaluation_subtype(manual_ades, gpt_output, drug))\n",
    "        \n",
    "    results = pd.DataFrame(results, columns=['drug_name', 'exclude', 'n_manual', 'n_gpt', 'tp', 'fp', 'fn', 'precision', 'recall', 'f1'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d669d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_granular(manual_ades, gpt_output, limit = 1000):\n",
    "    drugs = gpt_output['drug_name'].unique()\n",
    "    drugs_set = set()\n",
    "    results = []\n",
    "    for drug in tqdm(drugs):\n",
    "        drugs_set.add(drug)\n",
    "        if len(drugs_set) > limit:\n",
    "            break\n",
    "        \n",
    "        results.append(evaluation_subtype(manual_ades, gpt_output, drug, subtype = 'all'))\n",
    "        results.append(evaluation_subtype(manual_ades, gpt_output, drug, subtype = 'exact-meddra'))\n",
    "        results.append(evaluation_subtype(manual_ades, gpt_output, drug, subtype = 'non-meddra'))\n",
    "        results.append(evaluation_subtype(manual_ades, gpt_output, drug, subtype = 'negated'))\n",
    "        results.append(evaluation_subtype(manual_ades, gpt_output, drug, subtype = 'discontinuous'))\n",
    "\n",
    "    results = pd.DataFrame(results, columns=['drug_name', 'ade_type', 'n_manual', 'n_gpt', 'tp', 'fp', 'fn', 'precision', 'recall', 'f1'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37930311-07c7-4762-abd1-cb249c5bd25d",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed8cc025-3af6-4bea-826b-962eb8b36f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_file = 'data/train_drug_label_text.csv'\n",
    "manual_file = 'data/train_drug_label_text_manual_ades.csv'\n",
    "my_max = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22518e4d-ec19-4a56-9914-cd969a50cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = pd.read_csv(drug_file)\n",
    "manual_ades = pd.read_csv(manual_file)\n",
    "set_type = drug_file.split('/')[1].split('_')[0] # assuming file follows format \"train_...\" or \"test....\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ae7da-2a0e-4755-ae4d-4bced5f7f5a2",
   "metadata": {},
   "source": [
    "## Run GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e618b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6f04e8a-be72-4ad8-abfe-7b5d60c03a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open('./config.json'))\n",
    "\n",
    "organization = \"\"\n",
    "\n",
    "api_source = 'OpenAI'\n",
    "\n",
    "api_key = config[api_source]['openai_api_key'] #constants.AZURE_OPENAI_KEY\n",
    "api_endpoint = config[api_source]['openai_api_endpoint'] \n",
    "\n",
    "gpt_model = config[api_source][\"gpt_model\"]\n",
    "gpt_model = \"gpt-4-turbo-preview\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4b1bbd7-3b6c-42f5-a2af-04391ea86537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI_gpt-4-turbo-preview_fatal-prompt-v2_pharmexpert-v0_train'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nruns = 1\n",
    "\n",
    "system_options = {\n",
    "    \"pharmexpert-v0\": \"You are an expert in pharmacology.\",\n",
    "    \"pharmexpert-v1\": \"You are an expert in medical natural language processing, adverse drug reactions, pharmacology, and clinical trials.\"\n",
    "}\n",
    "\n",
    "prompt_options = {\n",
    "    \"fatal-prompt-v2\": \"\"\"\n",
    "Extract all adverse reactions as they appear, including all synonyms.\n",
    "mentioned in the text and provide them as a comma-separated list.\n",
    "If a fatal event is listed add 'death' to the list.\n",
    "The text is :'{}' \n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "system_name = \"pharmexpert-v0\"\n",
    "system_content = system_options[system_name]\n",
    "\n",
    "prompt_name = \"fatal-prompt-v2\"\n",
    "prompt = prompt_options[prompt_name]\n",
    "\n",
    "output_file_basename = '{}_{}_{}_{}_{}'.format(api_source, gpt_model, prompt_name, system_name, set_type)\n",
    "output_file_basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cdb9c192-ba44-4135-8d3c-7b6ba6644563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is a max\n",
    "new_rows = list()\n",
    "unique_drugs = set()\n",
    "for i, row in drugs.iterrows():\n",
    "    unique_drugs.add(row[\"drug_name\"])\n",
    "    if len(unique_drugs) > my_max: \n",
    "        break\n",
    "    if row['section_name'] != 'adverse reactions':\n",
    "        continue\n",
    "\n",
    "    new_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "492d7e82-894f-4c0f-bbf1-4de819b94b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [16:49<00:00,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0, time elapsed: 1009.4725449085236s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# run GPT\n",
    "for i in range(nruns):\n",
    "    run_key = \"{}_run{}\".format(output_file_basename, i)\n",
    "\n",
    "    if run_key in outputs:\n",
    "        print(f\"Run {run_key} already completed and stored. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    if os.path.exists('results/{}.csv'.format(run_key)):\n",
    "        gpt_output = pd.read_csv('results/{}.csv'.format(run_key))\n",
    "        outputs[run_key] = gpt_output\n",
    "        print(f\"Run {run_key} already completed and loaded from disk.\")\n",
    "        continue\n",
    "    \n",
    "    start = time.time()\n",
    "    results = list()\n",
    "    for row in tqdm(new_rows):\n",
    "        name, section = row['drug_name'], row['section_name']\n",
    "        text = row['section_text']\n",
    "        try:\n",
    "            gpt_out = extract_ade_terms(api_source, api_endpoint, gpt_model, system_content, prompt, text, api_key)\n",
    "            # time.sleep(5)\n",
    "            results.append([name, section, gpt_out])\n",
    "        except Exception as err:\n",
    "            print(f\"Encountered an exception for row: {name} {section}. Error message below:\")\n",
    "            print(err)\n",
    "            continue\n",
    "            \n",
    "    gpt_output = pd.DataFrame(\n",
    "        [r for r in results if r is not None],\n",
    "        columns=['drug_name', 'section_name', 'gpt_output']\n",
    "    )\n",
    "    end = time.time()\n",
    "\n",
    "    if gpt_output.shape[0] > 0:\n",
    "        outputs[run_key] = gpt_output\n",
    "        gpt_output.to_csv('results/{}.csv'.format(run_key))\n",
    "    \n",
    "    print(f\"Run: {run_key}, time elapsed: {end-start}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79125bf3",
   "metadata": {},
   "source": [
    "## Exact Match Algorithm\n",
    "\n",
    "TODO: Exact match really doesn't fit here any longer but we need it at least once to show how well (or poorly) it does. Refactor out into it's own notebook/script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "704c226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_key = 'exact_{}_{}_{}'.format(prompt_name, system_name, set_type)\n",
    "\n",
    "if not os.path.exists('results/{}.csv'.format(run_key)):\n",
    "    # load the meddra terms\n",
    "    fh = open('data/meddra_llt_pt_map.txt')\n",
    "    reader = csv.reader(fh, delimiter='|')\n",
    "    header = next(reader)\n",
    "\n",
    "    meddra_llt_terms = set()\n",
    "    meddra_pt_terms = set()\n",
    "\n",
    "    for row in reader:\n",
    "        meddra_llt_terms.add(row[1].lower())\n",
    "        meddra_pt_terms.add(row[4].lower())\n",
    "    \n",
    "    fh.close()\n",
    "\n",
    "    meddra_terms = meddra_llt_terms | meddra_pt_terms\n",
    "    len(meddra_llt_terms), len(meddra_pt_terms), len(meddra_terms)\n",
    "\n",
    "    results = list()\n",
    "    for row in tqdm(new_rows):\n",
    "        name, section = row['drug_name'], row['section_name']\n",
    "        text = row['section_text'].lower()\n",
    "        \n",
    "        found_terms = set()\n",
    "        for term in meddra_terms:\n",
    "            if text.find(term) != -1:\n",
    "                found_terms.add(term)\n",
    "        \n",
    "        exact_out = ', '.join(list(found_terms))\n",
    "        \n",
    "        results.append([name, section, exact_out])\n",
    "\n",
    "    exact_output = pd.DataFrame(\n",
    "        [r for r in results if r is not None],\n",
    "        columns=['drug_name', 'section_name', 'gpt_output']\n",
    "    )\n",
    "    exact_output.to_csv('results/{}.csv'.format(run_key))\n",
    "    \n",
    "    outputs[run_key] = exact_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7986085b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "787d7804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 138.73it/s]\n",
      "/var/folders/l5/4jn07y290nncb4wnyhsq33hh0000gt/T/ipykernel_12330/1080455710.py:3: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  overall_results = results_granular.groupby('ade_type')['tp', 'fp', 'fn'].apply(sum)\n",
      "/var/folders/l5/4jn07y290nncb4wnyhsq33hh0000gt/T/ipykernel_12330/1080455710.py:7: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  macro_results = results_granular.groupby('ade_type')['precision', 'recall', 'f1'].apply(np.mean)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3502: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3502: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3502: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3502: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3502: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt0\n",
      "                   tp     fp      fn  micro_precision  micro_recall  micro_f1  \\\n",
      "ade_type                                                                        \n",
      "all            3650.0  495.0  1466.0         0.880579      0.713448  0.788252   \n",
      "discontinuous    22.0    0.0   348.0         1.000000      0.059459  0.112245   \n",
      "exact-meddra   3253.0    0.0   736.0         1.000000      0.815493  0.898371   \n",
      "negated          12.0    0.0    19.0         1.000000      0.387097  0.558140   \n",
      "non-meddra      397.0    0.0   731.0         1.000000      0.351950  0.520656   \n",
      "\n",
      "               macro_precision  macro_recall  macro_f1  \n",
      "ade_type                                                \n",
      "all                   0.854821      0.736277  0.792026  \n",
      "discontinuous              NaN      0.062585       NaN  \n",
      "exact-meddra               NaN      0.828049       NaN  \n",
      "negated                    NaN      0.400000       NaN  \n",
      "non-meddra                 NaN      0.448830       NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:00<00:00, 134.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact\n",
      "                   tp      fp      fn  micro_precision  micro_recall  \\\n",
      "ade_type                                                               \n",
      "all            4064.0  6156.0  1273.0         0.397652      0.761476   \n",
      "discontinuous    19.0     0.0   369.0         1.000000      0.048969   \n",
      "exact-meddra   4037.0     0.0   126.0         1.000000      0.969733   \n",
      "negated          16.0     0.0    16.0         1.000000      0.500000   \n",
      "non-meddra       27.0     0.0  1148.0         1.000000      0.022979   \n",
      "\n",
      "               micro_f1  macro_precision  macro_recall  macro_f1  \n",
      "ade_type                                                          \n",
      "all            0.522466         0.355676      0.764204  0.475495  \n",
      "discontinuous  0.093366              NaN      0.062205       NaN  \n",
      "exact-meddra   0.984634              NaN      0.969178       NaN  \n",
      "negated        0.666667              NaN      0.519841       NaN  \n",
      "non-meddra     0.044925              NaN      0.020413       NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/l5/4jn07y290nncb4wnyhsq33hh0000gt/T/ipykernel_12330/1080455710.py:3: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  overall_results = results_granular.groupby('ade_type')['tp', 'fp', 'fn'].apply(sum)\n",
      "/var/folders/l5/4jn07y290nncb4wnyhsq33hh0000gt/T/ipykernel_12330/1080455710.py:7: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  macro_results = results_granular.groupby('ade_type')['precision', 'recall', 'f1'].apply(np.mean)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3502: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3502: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3502: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3502: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3502: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "for run_key, output in outputs.items():\n",
    "    results_granular = evaluation_granular(manual_ades, output)\n",
    "    overall_results = results_granular.groupby('ade_type')['tp', 'fp', 'fn'].apply(sum)\n",
    "    overall_results['micro_precision'] = overall_results['tp']/(overall_results['tp']+overall_results['fp'])\n",
    "    overall_results['micro_recall'] = overall_results['tp']/(overall_results['tp']+overall_results['fn'])\n",
    "    overall_results['micro_f1'] = (2 * overall_results['micro_precision'] * overall_results['micro_recall'])/(overall_results['micro_precision'] + overall_results['micro_recall']) # 2*tp_total/(2*tp_total+fp_total+fn_total)\n",
    "    macro_results = results_granular.groupby('ade_type')['precision', 'recall', 'f1'].apply(np.mean)\n",
    "    overall_results['macro_precision'] = macro_results['precision']\n",
    "    overall_results['macro_recall'] = macro_results['recall']\n",
    "    overall_results['macro_f1'] = macro_results['f1']\n",
    "    save_filename = 'results/{}_granular.csv'.format(run_key)\n",
    "\n",
    "    overall_results.to_csv(save_filename)\n",
    "    \n",
    "    print(run_key)\n",
    "    print(overall_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f04b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
