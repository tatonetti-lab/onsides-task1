{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706f8453-d366-4e8c-976c-90b59cf58197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "import concurrent\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from evaluation_functions import evaluate\n",
    "from openai_functions import extract_ade_terms\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db80a89-6744-4602-936e-c5457d547d20",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37930311-07c7-4762-abd1-cb249c5bd25d",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed8cc025-3af6-4bea-826b-962eb8b36f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "drug_file = 'data/train_drug_label_text.csv'\n",
    "manual_file = 'data/train_drug_label_text_manual_ades.csv'\n",
    "\n",
    "# test\n",
    "# drug_file = 'data/test_drug_label_text.csv'\n",
    "# manual_file = 'data/test_drug_label_text_manual_ades.csv'\n",
    "\n",
    "# my_max = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22518e4d-ec19-4a56-9914-cd969a50cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = pd.read_csv(drug_file)\n",
    "manual_ades = pd.read_csv(manual_file)\n",
    "set_type = drug_file.split('/')[1].split('_')[0] # assuming file follows format \"train_...\" or \"test....\"\n",
    "\n",
    "all_sections = drugs.query(\"section_name != 'all-concat'\").groupby('drug_name')['section_text'].apply(' '.join).reset_index()\n",
    "all_sections.insert(1, \"section_name\", [\"all-concat\" for _ in range(all_sections.shape[0])])\n",
    "drugs = pd.concat([drugs, all_sections])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c24736c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(340, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ae7da-2a0e-4755-ae4d-4bced5f7f5a2",
   "metadata": {},
   "source": [
    "## Run GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e618b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6f04e8a-be72-4ad8-abfe-7b5d60c03a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open('./config.json'))\n",
    "\n",
    "organization = \"\"\n",
    "\n",
    "api_source = 'OpenAI'\n",
    "\n",
    "api_key = config[api_source]['openai_api_key'] #constants.AZURE_OPENAI_KEY\n",
    "api_endpoint = config[api_source]['openai_api_endpoint'] \n",
    "\n",
    "gpt_model = config[api_source][\"gpt_model\"]\n",
    "# gpt_model = \"gpt-4-turbo-preview\"\n",
    "# gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "temperature = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4b1bbd7-3b6c-42f5-a2af-04391ea86537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nruns = 3\n",
    "\n",
    "system_options = {\n",
    "    \"no-system-prompt\": \"\",\n",
    "    \"pharmexpert-v0\": \"You are an expert in pharmacology.\",\n",
    "    \"pharmexpert-v1\": \"You are an expert in medical natural language processing, adverse drug reactions, pharmacology, and clinical trials.\"\n",
    "}\n",
    "\n",
    "prompt_options = {\n",
    "    \"fatal-prompt-v2\": \"\"\"\n",
    "Extract all adverse reactions as they appear, including all synonyms.\n",
    "mentioned in the text and provide them as a comma-separated list.\n",
    "If a fatal event is listed add 'death' to the list.\n",
    "The text is :'{}' \n",
    "\"\"\",\n",
    "    \"fatal-prompt-v3\": \"\"\"\n",
    "Extract all adverse reactions as they appear, including all synonyms.\n",
    "mentioned in the text and provide them as a comma-separated list. If a\n",
    "negated adverse reaction appears extract it and include a <negated> tag.\n",
    "If a fatal event is listed add 'death' to the list.\n",
    "The text is :'{}' \n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "system_name = \"pharmexpert-v0\"\n",
    "system_content = system_options[system_name]\n",
    "\n",
    "prompt_name = \"fatal-prompt-v2\"\n",
    "prompt = prompt_options[prompt_name]\n",
    "\n",
    "gpt_params = [f\"temp{temperature}\"]\n",
    "\n",
    "output_file_basename = '{}_{}_{}_{}_{}_{}'.format(api_source, gpt_model, prompt_name, system_name, '-'.join(gpt_params), set_type)\n",
    "output_file_basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "492d7e82-894f-4c0f-bbf1-4de819b94b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run0\n",
      "Run OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run0 started, loading from disk and pick up from where it was left off.\n",
      "Loaded 340 rows from file since they were already run.\n",
      "There remains 0 rows to run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run0, time elapsed: 0.2753791809082031s.\n",
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run1\n",
      "Run OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run1 started, loading from disk and pick up from where it was left off.\n",
      "Loaded 340 rows from file since they were already run.\n",
      "There remains 0 rows to run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run1, time elapsed: 0.25836968421936035s.\n",
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run2\n",
      "Run OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run2 started, loading from disk and pick up from where it was left off.\n",
      "Loaded 340 rows from file since they were already run.\n",
      "There remains 0 rows to run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run2, time elapsed: 0.2555088996887207s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# run GPT\n",
    "for i in range(nruns):\n",
    "    run_key = \"{}_run{}\".format(output_file_basename, i)\n",
    "    print(run_key)\n",
    "    if run_key in outputs:\n",
    "        print(f\"Run {run_key} already started will pick up from where it was left off.\")\n",
    "    elif os.path.exists('results/{}.csv'.format(run_key)):\n",
    "        gpt_output = pd.read_csv('results/{}.csv'.format(run_key))\n",
    "        outputs[run_key] = gpt_output\n",
    "        print(f\"Run {run_key} started, loading from disk and pick up from where it was left off.\")\n",
    "    \n",
    "    start = time.time()\n",
    "    results = list()\n",
    "    rows_to_run = list()\n",
    "    for _, row in drugs.iterrows():\n",
    "        name, section = row['drug_name'], row['section_name']\n",
    "\n",
    "        if run_key in outputs:\n",
    "            prev_run_results = outputs[run_key].query(f\"drug_name == '{name}'\").query(f\"section_name == '{section}'\")\n",
    "            if prev_run_results.shape[0]==1:\n",
    "                results.append([name, section, prev_run_results.gpt_output.values[0]])\n",
    "            else:\n",
    "                rows_to_run.append(row)\n",
    "        else:\n",
    "            rows_to_run.append(row)\n",
    "        \n",
    "    print(f\"Loaded {len(results)} rows from file since they were already run.\")\n",
    "    print(f\"There remains {len(rows_to_run)} rows to run.\")\n",
    "\n",
    "    def run_iteration(row):\n",
    "        name, section = row['drug_name'], row['section_name']\n",
    "        text = row['section_text']\n",
    "        try:\n",
    "            gpt_out = extract_ade_terms(api_source, config, gpt_model, system_content, prompt, text, temperature)\n",
    "            return [name, section, gpt_out]\n",
    "        except Exception as err:\n",
    "            print(f\"Encountered an exception for row: {name} {section}. Error message below:\")\n",
    "            print(err)\n",
    "            return None\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as exec:\n",
    "        results.extend(list(tqdm(\n",
    "            exec.map(run_iteration, rows_to_run), \n",
    "            total=len(rows_to_run)\n",
    "        )))\n",
    "    \n",
    "    gpt_output = pd.DataFrame(\n",
    "        [r for r in results if r is not None],\n",
    "        columns=['drug_name', 'section_name', 'gpt_output']\n",
    "    )\n",
    "    end = time.time()\n",
    "    \n",
    "    if gpt_output.shape[0] > 0:\n",
    "        outputs[run_key] = gpt_output\n",
    "        gpt_output.to_csv('results/{}.csv'.format(run_key))\n",
    "    \n",
    "    print(f\"Run: {run_key}, time elapsed: {end-start}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3651b99c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7986085b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3e1252e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run0\n",
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run1\n",
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run2\n"
     ]
    }
   ],
   "source": [
    "for run_key in sorted(outputs.keys()):\n",
    "    print(run_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6c19d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = {'thrombocytopenia', 'anemia', 'death', 'acute renal failure', 'pulmonary toxicity', 'hepatic failure', 'nausea', 'infusion reactions', 'pulmonary hypertension', 'hepatic toxicity', 'decreased lymphocyte', 'dyspnea', 'tumor lysis syndrome', 'diarrhea', 'fatigue', 'pyrexia', 'edema peripheral', 'hypertension', 'decreased platelets', 'cardiac toxicities', 'hemolytic uremic syndrome', 'headache', 'venous thrombosis', 'thrombotic thrombocytopenic purpura', 'cough', 'posterior reversible encephalopathy syndrome'}\n",
    "man = {'cardiac failure congestive', 'died', 'thrombocytopenia', 'decreased total white blood cell count', 'leukopenia', 'dizziness', 'deafness', 'pulmonary toxicity', 'hepatic failure', 'pain in extremity', 'asthenia', 'cataract', 'rash', 'bronchopneumonia', 'hypophosphatemia', 'hypoalbuminemia', 'bronchitis', 'tumor lysis syndrome', 'diarrhea', 'decreased absolute neutrophil count', 'pyrexia', 'edema peripheral', 'musculoskeletal pain', 'muscle spasm', 'hypertension', 'ttp', 'cardiac toxicities', 'decreased phosphorus', 'myocardial ischemia', 'infection adverse events', 'anxiety', 'hypomagnesemia', 'decreased potassium', 'posterior reversible encephalopathy syndrome', 'insomnia', 'mortality', 'decreased appetite', 'hypoesthesia', 'dysphonia', 'viral infection', 'renal failure', 'hypercalcemia', 'febrile neutropenia', 'pain', 'lymphopenia', 'renal disorders', 'respiratory tract infection', 'infusion reactions', 'disease progression', 'congestive heart failure', 'pruritus', 'pneumonia', 'upper respiratory tract infection', 'hepatic toxicity', 'renal impairment', 'chills', 'muscle spasms', 'back pain', 'deaths', 'epistaxis', 'decreased sodium', 'hemolytic uremic syndrome', 'oropharyngeal pain', 'thrombotic thrombocytopenic purpura', 'dehydration', 'hyperkalemia', 'musculoskeletal chest pain', 'hypocalcemia', 'hyperuricemia', 'myalgia', 'dyspnea exertional', 'peripheral neuropathies nec', 'blurred vision', 'erythema', 'delirium', 'acute renal failure', 'renal failure acute', 'nausea', 'vomiting', 'nasopharyngitis', 'sepsis', 'hypotension', 'decreased lymphocyte', 'fatigue', 'fatal', 'hypertensive crisis', 'vision blurred', 'deep vein thrombosis', 'infusion site reaction', 'embolic and thrombotic events, venous', 'headache', 'cardiac failure', 'decreased lymphocytes', 'cardiac adverse events', 'hypertensive emergency', 'pulmonary edema', 'pulmonary embolism', 'myocardial infarction', 'decreased hemoglobin', 'influenza', 'paresthesia', 'hyperglycemia', 'neutropenia', 'abdominal pain upper', 'anemia', 'toothache', 'cardiac disorders', 'multi-organ failure', 'cardiac arrest', 'pres', 'hyperhidrosis', 'pulmonary hypertension', 'hypokalemia', 'dyspnea', 'dyspepsia', 'urinary tract infection', 'abdominal pain', 'decreased platelets', 'renal adverse events', 'venous thrombosis', 'muscular weakness', 'infections', 'cough', 'hus', 'arthralgia', 'multiple myeloma', 'constipation', 'hyponatremia'}\n",
    "len(man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "787d7804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running strict evaluation and saving results to disk.\n",
      "OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v0_temp0.5_train_run0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:02<00:00, 39.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v0_temp0.5_train_run1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:02<00:00, 40.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v0_temp0.5_train_run2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:02<00:00, 40.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0.5_train_run0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:02<00:00, 40.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0.5_train_run1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:02<00:00, 40.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0.5_train_run2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:02<00:00, 40.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp1.0_train_run0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:02<00:00, 40.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp1.0_train_run1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:02<00:00, 40.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp1.0_train_run2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:02<00:00, 40.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp1.5_train_run0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:02<00:00, 39.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running lenient evaluation and saving results to disk.\n",
      "OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v0_temp0.5_train_run0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:12<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v0_temp0.5_train_run1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:13<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_pharmexpert-v0_temp0.5_train_run2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:12<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0.5_train_run0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:21<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0.5_train_run1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:20<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0.5_train_run2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:20<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp1.0_train_run0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:20<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp1.0_train_run1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:21<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp1.0_train_run2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:20<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp1.5_train_run0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/101 [00:06<00:27,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/l5/4jn07y290nncb4wnyhsq33hh0000gt/T/ipykernel_65176/1979341734.py\", line 2, in <module>\n",
      "    evaluate(outputs, manual_ades, 'lenient')\n",
      "  File \"/Users/TatonettiN/Projects/onsides-task1/evaluation_functions.py\", line 112, in evaluate\n",
      "    if eval_method == 'embed':\n",
      "  File \"/Users/TatonettiN/Projects/onsides-task1/evaluation_functions.py\", line 98, in evaluation_granular\n",
      "    else:\n",
      "  File \"/Users/TatonettiN/Projects/onsides-task1/evaluation_functions.py\", line 68, in evaluation_subtype\n",
      "  File \"/Users/TatonettiN/Projects/onsides-task1/common_string.py\", line 42, in common_lenient_performance\n",
      "    common = [longest_common_substring_percentage(man_out, x) for x in gpt_output]\n",
      "  File \"/Users/TatonettiN/Projects/onsides-task1/common_string.py\", line 42, in <listcomp>\n",
      "    common = [longest_common_substring_percentage(man_out, x) for x in gpt_output]\n",
      "  File \"/Users/TatonettiN/Projects/onsides-task1/common_string.py\", line 16, in longest_common_substring_percentage\n",
      "    assert min(len(s1), len(s2)) > 0, \"One of the given string is empty\"\n",
      "AssertionError: One of the given string is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1428, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1319, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1172, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1087, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 969, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encountered an exception for row: SAPHRIS all-concat. Error message below:\n",
      "Request timed out.\n"
     ]
    }
   ],
   "source": [
    "evaluate(outputs, manual_ades, 'strict')\n",
    "evaluate(outputs, manual_ades, 'lenient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d376cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using embeddings -- run this once:\n",
    "# get embeddings for manual annotation --- this part is slow -- but should take <5 min\n",
    "embed_model_name = 'llmrails/ember-v1'\n",
    "embed_model = SentenceTransformer(embed_model_name)\n",
    "man_embeds = embed_model.encode(manual_ades['reaction_string'].tolist())\n",
    "manual_ades['embeds'] = list(man_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11058bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running embed evaluation and saving results to disk.\n",
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run0\n",
      "saving results to results/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run0_ember-v1_granular.csv and results/OpenAI_gpt-4-1106-preview_fatal-prompt-v2_pharmexpert-v0_temp0_train_run0_ember-v1_overall.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TatonettiN/Projects/onsides-task1/evaluation_functions.py:41: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  output['gpt_output'] = output['gpt_output'].str.lower().str.replace('.', '').str.replace('\\n-', ', ').str.split(', ')\n",
      "  9%|▉         | 9/101 [00:15<02:41,  1.75s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmanual_ades\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_model_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/onsides-task1/evaluation_functions.py:159\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(outputs, manual_ades, eval_method, embed_model_name, embed_model)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mprint\u001b[39m(run_key)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaving results to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgranular_save_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverall_save_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 159\u001b[0m results_granular \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation_granular\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanual_ades\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43membed_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m overall_results \u001b[38;5;241m=\u001b[39m results_granular\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msection\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124made_type\u001b[39m\u001b[38;5;124m'\u001b[39m])[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfn\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39msum(min_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m    161\u001b[0m overall_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro_precision\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m overall_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m/\u001b[39m(overall_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39moverall_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfp\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Projects/onsides-task1/evaluation_functions.py:139\u001b[0m, in \u001b[0;36mevaluation_granular\u001b[0;34m(manual_ades, gpt_output, eval_method, embed_model)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m                 man_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(manual_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreaction_string\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list())\n\u001b[0;32m--> 139\u001b[0m             results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mevaluation_subtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mman_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpt_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43meval_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msection\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msection\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    142\u001b[0m results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrug_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msection\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124made_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_manual\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_gpt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/Projects/onsides-task1/evaluation_functions.py:81\u001b[0m, in \u001b[0;36mevaluation_subtype\u001b[0;34m(manual, gpt_vals, drug, section, subtype, eval_method)\u001b[0m\n\u001b[1;32m     79\u001b[0m     [TP, FP, FN] \u001b[38;5;241m=\u001b[39m common_lenient_performance(gpt_vals, manual)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m eval_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membed\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 81\u001b[0m     [TP, FP, FN] \u001b[38;5;241m=\u001b[39m \u001b[43membed_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpt_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.6681796\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     84\u001b[0m     precision \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n",
      "File \u001b[0;32m~/Projects/onsides-task1/evaluation_functions.py:60\u001b[0m, in \u001b[0;36membed_evaluation\u001b[0;34m(man_df, gpt_embeds, threshold)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError in embed_evaluation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (term, gpt_emb) \u001b[38;5;129;01min\u001b[39;00m gpt_embeds\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 60\u001b[0m     sims \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(cos_sim(gpt_emb, man_emb)) \u001b[38;5;28;01mfor\u001b[39;00m (term, man_emb) \u001b[38;5;129;01min\u001b[39;00m man_df\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmax(sims) \u001b[38;5;241m<\u001b[39m threshold:\n",
      "File \u001b[0;32m~/Projects/onsides-task1/evaluation_functions.py:60\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError in embed_evaluation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (term, gpt_emb) \u001b[38;5;129;01min\u001b[39;00m gpt_embeds\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 60\u001b[0m     sims \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(\u001b[43mcos_sim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpt_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mman_emb\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m (term, man_emb) \u001b[38;5;129;01min\u001b[39;00m man_df\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmax(sims) \u001b[38;5;241m<\u001b[39m threshold:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sentence_transformers/util.py:48\u001b[0m, in \u001b[0;36mcos_sim\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(b\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     46\u001b[0m     b \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m a_norm \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m b_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mnormalize(b, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmm(a_norm, b_norm\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/functional.py:4719\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(input, p, dim, eps, out)\u001b[0m\n\u001b[1;32m   4717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(normalize, (\u001b[38;5;28minput\u001b[39m, out), \u001b[38;5;28minput\u001b[39m, p\u001b[38;5;241m=\u001b[39mp, dim\u001b[38;5;241m=\u001b[39mdim, eps\u001b[38;5;241m=\u001b[39meps, out\u001b[38;5;241m=\u001b[39mout)\n\u001b[1;32m   4718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4719\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mclamp_min(eps)\u001b[38;5;241m.\u001b[39mexpand_as(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   4720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m/\u001b[39m denom\n\u001b[1;32m   4721\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_tensor.py:708\u001b[0m, in \u001b[0;36mTensor.norm\u001b[0;34m(self, p, dim, keepdim, dtype)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    706\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mnorm, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, p\u001b[38;5;241m=\u001b[39mp, dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39mkeepdim, dtype\u001b[38;5;241m=\u001b[39mdtype\n\u001b[1;32m    707\u001b[0m     )\n\u001b[0;32m--> 708\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/functional.py:1611\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1609\u001b[0m _p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m p\n\u001b[1;32m   1610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1613\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(\u001b[38;5;28minput\u001b[39m, _p, _dim, keepdim, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate(outputs, manual_ades, 'embed', embed_model=embed_model, embed_model_name=embed_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e113a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
