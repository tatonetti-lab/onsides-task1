{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0adcd0c-5be6-42b0-971d-ca9d80629940",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai json requests os tiktoken time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d237598f-0a02-4d36-ac24-b67bbd58e756",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT DATA\n",
    "labels = pd.read_csv(\"train_drug_label_text_remove_unnecessary_info.csv\")\n",
    "manual_ades = pd.read_csv('train_drug_label_text_manual_ades.csv')\n",
    "subsection_results = pd.read_csv(\"subsection_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5aee75-b052-4f9f-b507-f2e81a5eddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 drugs with lowest recall \n",
    "subsection_results = subsection_results.sort_values('recall')\n",
    "bottom = subsection_results[:10].drug_name.to_list()\n",
    "bottom_ades = []\n",
    "for drug in tqdm(bottom):\n",
    "    drug_df = manual_ades[manual_ades['drug_name'] == drug]\n",
    "    manual = set(drug_df['reaction_string'].str.lower())\n",
    "    manual = list(manual)\n",
    "    bottom_ades.append(manual)\n",
    "bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ab6bda-99a3-4f4e-94f9-06f939c9cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results['drug_name'].isin(bottom)].sort_values('drug_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e4e1df-0081-4bac-a226-100773fcbd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe of 10 drugs with lowest recall \n",
    "\n",
    "finetune = []\n",
    "for i in range(len(bottom)):\n",
    "    finetune.append([bottom[i], bottom_ades[i]])\n",
    "    # finetune.append([bottom, bottom_ades])\n",
    "finetune = pd.DataFrame(finetune, columns = [\"drug_name\", \"ades\"])\n",
    "finetune.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52c0803-8fe8-426e-805f-b41495d67580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to concatenate section_text for specific drugs\n",
    "\n",
    "def concatenate_texts(df, drug_list):\n",
    "    # Filter the DataFrame for the drugs in the list\n",
    "    filtered_df = df[df['drug_name'].isin(drug_list)]\n",
    "\n",
    "    # Group by drug_name and concatenate section_text\n",
    "    concatenated_df = filtered_df.groupby('drug_name')['section_text'].apply(' '.join).reset_index()\n",
    "\n",
    "    return concatenated_df\n",
    "\n",
    "# Using the function\n",
    "result_df = concatenate_texts(labels, bottom)\n",
    "result_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02131bb6-5576-4be3-bc93-0c461f6ee98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_json(labels, result_df, finetune):\n",
    "    lst = []\n",
    "    for drug in labels:\n",
    "        # Get user content and convert to string if it's a list\n",
    "        user_content = result_df[result_df['drug_name'] == drug]['section_text'].iloc[0] if not result_df[result_df['drug_name'] == drug].empty else \"\"\n",
    "        if isinstance(user_content, list):\n",
    "            user_content = ' '.join(user_content)  # or use str(user_content) for list-like string\n",
    "\n",
    "        # Get assistant content and convert to string if it's a list\n",
    "        assistant_content = finetune[finetune['drug_name'] == drug]['ades'].iloc[0] if not finetune[finetune['drug_name'] == drug].empty else \"\"\n",
    "        if isinstance(assistant_content, list):\n",
    "            assistant_content = ' '.join(assistant_content)  # or use str(assistant_content) for list-like string\n",
    "\n",
    "        lst.append({\"messages\": [{\"role\": \"system\", \"content\": \"You are an expert in pharmacology.\"},\n",
    "                                 {\"role\": \"user\", \"content\": user_content},\n",
    "                                 {\"role\": \"assistant\", \"content\": assistant_content}]})\n",
    "    return lst\n",
    "\n",
    "# Generate the list of dictionaries\n",
    "json_list = generate_json(bottom, result_df, finetune)\n",
    "\n",
    "# Output to a JSONL file\n",
    "with open('finetuned_bottom_data.jsonl', 'w') as file:\n",
    "    for entry in json_list:\n",
    "        json.dump(entry, file)\n",
    "        file.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295fcfd0-3be5-470f-8c58-4fbcba1bdc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training set\n",
    "with open('finetuned_bottom_data.jsonl', 'r', encoding='utf-8') as f:\n",
    "    finetuned_data = [json.loads(line) for line in f]\n",
    "\n",
    "# Training dataset stats\n",
    "print(\"Number of examples in finetuned set:\", len(finetuned_data))\n",
    "print(\"First example in finetuned set:\")\n",
    "for message in finetuned_data[5][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5620bc0a-4fb1-4254-9210-fa31d9751f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7836ee56-a780-49b6-b13a-db82a4c45ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of tokens \n",
    "\n",
    "import json\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\") # default encoding used by gpt-4, turbo, and text-embedding-ada-002 models\n",
    "\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            # if isinstance(value, list):\n",
    "            #     value = str(value)\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            # if isinstance(message[\"content\"], list):\n",
    "            #     message[\"content\"] = str(message[\"content\"])\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "files = ['finetuned_bottom_data.jsonl']\n",
    "\n",
    "for file in files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "\n",
    "    total_tokens = []\n",
    "    assistant_tokens = []\n",
    "\n",
    "    for ex in dataset:\n",
    "        messages = ex.get(\"messages\", {})\n",
    "        total_tokens.append(num_tokens_from_messages(messages))\n",
    "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "    print_distribution(total_tokens, \"total tokens\")\n",
    "    print_distribution(assistant_tokens, \"assistant tokens\")\n",
    "    print('*' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de17b4cb-68a5-440c-af21-6a74f92f62c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload fine-tuning files\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  # azure_endpoint = os.getenv(\"https://onsides-gpt-finetuning.openai.azure.com/\"), \n",
    "  # api_key=os.getenv(\"1cc983d783784fcf9564848ea6cb7cc4\"),  \n",
    "  azure_endpoint = \"https://onsides-gpt-finetuning.openai.azure.com/\",\n",
    "  api_key= API_KEY, \n",
    "  api_version=\"2023-12-01-preview\"  # This API version or later is required to access fine-tuning for turbo/babbage-002/davinci-002\n",
    ")\n",
    "\n",
    "training_file_name = 'finetuned_bottom_data.jsonl'\n",
    "\n",
    "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
    "\n",
    "training_response = client.files.create(\n",
    "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612750b-ad87-4c9e-8bae-f195f71c0d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate fine-tune\n",
    "\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    model=\"gpt-35-turbo-0613\", # Enter base model name. Note that in Azure OpenAI the model name contains dashes and cannot contain dot/period characters. \n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.id)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7f7a8-8fcf-4529-9f54-fc3fad975655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track training status\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "status = response.status\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(10)\n",
    "    \n",
    "    response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    print(response.model_dump_json(indent=2))\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = response.status\n",
    "    print(f'Status: {status}')\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f'Fine-tuning job {job_id} finished with status: {status}')\n",
    "\n",
    "# List all fine-tuning jobs for this resource.\n",
    "print('Checking other fine-tune jobs for this resource.')\n",
    "response = client.fine_tuning.jobs.list()\n",
    "print(f'Found {len(response.data)} fine-tune jobs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da44c99-9b75-437d-9ed4-61a69fe8a7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve fine_tuned_model name\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(response.model_dump_json(indent=2))\n",
    "fine_tuned_model = response.fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f91f4-98fa-4699-aa32-91ea69d2d5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = AZURE_ENDPOINT, \n",
    "  api_key= API_KEY,  \n",
    "  api_version=\"2023-05-15\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-35-finetuned-bottomlabels\", # model = \"Custom deployment name you chose for your fine-tuning model\"\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in pharmacology.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are the adverse drug events for the drug CHOLINE\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
