{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706f8453-d366-4e8c-976c-90b59cf58197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import concurrent\n",
    "import time\n",
    "import json\n",
    "from common_string import common_lenient_performance\n",
    "\n",
    "from Llamasgard import CodeLlama\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db80a89-6744-4602-936e-c5457d547d20",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8759fb31-5cee-46e8-a65f-36bf14b08730",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed0377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_extraction(system_content, prompt, text, temperature):\n",
    "    llm=CodeLlama(system=system_content, temperature=temperature, max_new_tokens=2048)\n",
    "    response = llm(prompt=prompt.format(text))\n",
    "    return response\n",
    "\n",
    "def perform_cleanup(extraction, openai_api):\n",
    "    client = OpenAI(api_key=openai_api)\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"\"\"The following text is an extraction of adverse event terms from a drug label. Please remove any preamble or postamble from the list and turn the list of ADEs into a comma separated list. \n",
    "The text: {}\"\"\".format(extraction)\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        temperature=0,\n",
    "    )\n",
    "    term = chat_completion.choices[0].message.content\n",
    "    return term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98fa878b-b40a-4895-808e-9574b7d004c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for extracting \n",
    "def extract_ade_terms(config,system_content, prompt, text, temperature):\n",
    "  extraction = perform_extraction(system_content, prompt, text, temperature)\n",
    "  extraction = perform_cleanup(extraction, config['OpenAI']['openai_api_key'])\n",
    "  return extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd0bffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_subtype(manual_ades, gpt_output, drug, section='adverse reactions', subtype = 'all', lenient=False):\n",
    "    '''\n",
    "    For a given drug, evaluate the performance of GPT on a given subtype of ADEs. \n",
    "    '''\n",
    "    \n",
    "    drug_df = manual_ades.query(\"(drug_name == '{}') & (section_name == '{}')\".format(drug, section))\n",
    "    if subtype == 'exact-meddra': drug_df = drug_df[drug_df.meddra_exact_term == 1]\n",
    "    if subtype == 'non-meddra': drug_df = drug_df[drug_df.meddra_exact_term == 0]\n",
    "    if subtype == 'negated': drug_df = drug_df[drug_df.negated_term == 1]\n",
    "    if subtype == 'discontinuous': drug_df = drug_df[drug_df.discontinuous_term == 1]\n",
    "\n",
    "    \n",
    "    manual = set(drug_df['reaction_string'].to_list())\n",
    "    gpt_drug = (gpt_output[\n",
    "        (gpt_output['drug_name'] == drug)\n",
    "        &\n",
    "        (gpt_output['section_name'] == \"adverse reactions\")\n",
    "        ][\"gpt_output\"].astype(str)\n",
    "        .str.lower()\n",
    "        .str.replace('\\n-', ', ')\n",
    "        .str.split(\",\").tolist())\n",
    "    \n",
    "    try:\n",
    "        gpt_drug = [x.strip() for x in gpt_drug[0] if x]\n",
    "        gpt_drug = set(gpt_drug)\n",
    "    except:\n",
    "        return [drug, subtype, len(manual), len(gpt_drug), np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "        \n",
    "    if not lenient:    \n",
    "        #overall\n",
    "        TP = len(manual.intersection(gpt_drug))\n",
    "        FP = len(gpt_drug.difference(manual))\n",
    "        FN = len(manual.difference(gpt_drug))\n",
    "        if TP == 0 and FP == 0:\n",
    "            precision = np.NAN\n",
    "        else:\n",
    "            precision = TP/(TP+FP)\n",
    "        if TP == 0 and FN == 0:\n",
    "            recall = np.NAN\n",
    "        else:\n",
    "            recall = TP/(TP+FN)\n",
    "        if precision != 0 and recall != 0:\n",
    "            f1 = (2 * precision * recall)/(precision + recall)# 2*TP/(2*TP+FP+FN)\n",
    "        else:\n",
    "            f1 = np.NAN\n",
    "    else:\n",
    "        [TP, FP, FN, precision, recall, f1] = common_lenient_performance(gpt_drug, manual)\n",
    "    \n",
    "    if subtype != 'all':\n",
    "            # these can't be computed for the subtypes\n",
    "            precision = np.nan\n",
    "            f1 = np.nan\n",
    "            FP = np.nan\n",
    "    \n",
    "    return [drug, section, subtype, len(manual), len(gpt_drug), TP, FP, FN, precision, recall, f1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8c6cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(manual_ades, gpt_output, lenient=False, limit = 1000):\n",
    "    drugs = gpt_output['drug_name'].unique()\n",
    "    drugs_set = set()\n",
    "    results = []\n",
    "    for drug in tqdm(drugs):\n",
    "            results.append(evaluation_subtype(manual_ades, gpt_output, drug, lenient))        \n",
    "    results = pd.DataFrame(results, columns=['drug_name', 'exclude', 'n_manual', 'n_gpt', 'tp', 'fp', 'fn', 'precision', 'recall', 'f1'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d669d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_granular(manual_ades, gpt_output, limit = 1000, lenient=False):\n",
    "    drugs = gpt_output['drug_name'].unique()\n",
    "    drugs_set = set()\n",
    "    results = []\n",
    "    for drug in tqdm(drugs):\n",
    "        drugs_set.add(drug)\n",
    "        if len(drugs_set) > limit:\n",
    "            break\n",
    "        \n",
    "        for section in ['adverse reactions', 'warnings and precautions','boxed warnings']:\n",
    "            for subtype in ['all', 'exact-medra', 'non-meddra', 'negated', 'discontinuous']:\n",
    "                results.append(evaluation_subtype(manual_ades, gpt_output, drug, section, subtype, lenient))\n",
    "\n",
    "    results = pd.DataFrame(results, columns=['drug_name', 'section', 'ade_type', 'n_manual', 'n_gpt', 'tp', 'fp', 'fn', 'precision', 'recall', 'f1'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37930311-07c7-4762-abd1-cb249c5bd25d",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed8cc025-3af6-4bea-826b-962eb8b36f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_file = 'data/train_drug_label_text.csv'\n",
    "manual_file = 'data/train_drug_label_text_manual_ades.csv'\n",
    "my_max = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22518e4d-ec19-4a56-9914-cd969a50cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = pd.read_csv(drug_file)\n",
    "manual_ades = pd.read_csv(manual_file)\n",
    "set_type = drug_file.split('/')[1].split('_')[0] # assuming file follows format \"train_...\" or \"test....\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ae7da-2a0e-4755-ae4d-4bced5f7f5a2",
   "metadata": {},
   "source": [
    "## Run Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e618b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6f04e8a-be72-4ad8-abfe-7b5d60c03a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open('./config.json'))\n",
    "\n",
    "gpt_model = 'code-llama-34b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4b1bbd7-3b6c-42f5-a2af-04391ea86537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'code-llama-34b_fatal-prompt-v2_pharmexpert-v1_temp0_train'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nruns = 1\n",
    "temperature = 0\n",
    "\n",
    "system_options = {\n",
    "    \"no-system-prompt\": \"\",\n",
    "    \"pharmexpert-v0\": \"You are an expert in pharmacology.\",\n",
    "    \"pharmexpert-v1\": \"You are an expert in medical natural language processing, adverse drug reactions, pharmacology, and clinical trials.\"\n",
    "}\n",
    "\n",
    "prompt_options = {\n",
    "    \"fatal-prompt-v2\": \"\"\"\n",
    "Extract all adverse reactions as they appear, including all synonyms.\n",
    "mentioned in the text and provide them as a comma-separated list.\n",
    "If a fatal event is listed add 'death' to the list.\n",
    "The text is :'{}' \n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "system_name = \"pharmexpert-v1\"\n",
    "system_content = system_options[system_name]\n",
    "\n",
    "prompt_name = \"fatal-prompt-v2\"\n",
    "prompt = prompt_options[prompt_name]\n",
    "\n",
    "gpt_params = [f\"temp{temperature}\"]\n",
    "\n",
    "output_file_basename = '{}_{}_{}_{}_{}'.format(gpt_model, prompt_name, system_name, '-'.join(gpt_params), set_type)\n",
    "output_file_basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "492d7e82-894f-4c0f-bbf1-4de819b94b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code-llama-34b_fatal-prompt-v2_pharmexpert-v1_temp0_train_run0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 39/239 [50:39<5:22:04, 96.62s/it]  "
     ]
    }
   ],
   "source": [
    "# run Llama\n",
    "for i in range(nruns):\n",
    "    run_key = \"{}_run{}\".format(output_file_basename, i)\n",
    "    print(run_key)\n",
    "    if run_key in outputs:\n",
    "        print(f\"Run {run_key} already started will pick up from where it was left off.\")\n",
    "    elif os.path.exists('results/{}.csv'.format(run_key)):\n",
    "        gpt_output = pd.read_csv('results/{}.csv'.format(run_key))\n",
    "        outputs[run_key] = gpt_output\n",
    "        print(f\"Run {run_key} started, loading from disk and pick up from where it was left off.\")\n",
    "    \n",
    "    start = time.time()\n",
    "    results = list()\n",
    "    for _, row in tqdm(drugs.iterrows(), total=drugs.shape[0]):\n",
    "        name, section = row['drug_name'], row['section_name']\n",
    "\n",
    "        if run_key in outputs:\n",
    "            prev_run_results = outputs[run_key].query(f\"drug_name == '{name}'\").query(f\"section_name == '{section}'\")\n",
    "            if prev_run_results.shape[0]==1:\n",
    "                results.append([name, section, prev_run_results.gpt_output.values[0]])\n",
    "                continue\n",
    "        \n",
    "        text = row['section_text'][:15000]\n",
    "        try:\n",
    "            gpt_out = extract_ade_terms(config, system_content, prompt, text, temperature)\n",
    "            results.append([name, section, gpt_out])\n",
    "        except Exception as err:\n",
    "            print(f\"Encountered an exception for row: {name} {section}. Error message below:\")\n",
    "            print(err)\n",
    "            continue\n",
    "            \n",
    "    gpt_output = pd.DataFrame(\n",
    "        [r for r in results if r is not None],\n",
    "        columns=['drug_name', 'section_name', 'gpt_output']\n",
    "    )\n",
    "    end = time.time()\n",
    "    \n",
    "    if gpt_output.shape[0] > 0:\n",
    "        outputs[run_key] = gpt_output\n",
    "        gpt_output.to_csv('results/{}.csv'.format(run_key))\n",
    "    \n",
    "    print(f\"Run: {run_key}, time elapsed: {end-start}s.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7986085b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "787d7804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:01<00:00, 50.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_no-system-prompt_temp0_train_run0\n",
      "                     section       ade_type    tp      fp    fn  \\\n",
      "0          adverse reactions            all  3905   407.0  1432   \n",
      "1          adverse reactions  discontinuous    46     NaN   342   \n",
      "2          adverse reactions    exact-medra  3905     NaN  1432   \n",
      "3          adverse reactions        negated    15     NaN    17   \n",
      "4          adverse reactions     non-meddra   439     NaN   736   \n",
      "5             boxed warnings            all    69  4243.0   193   \n",
      "6             boxed warnings  discontinuous     2     NaN    31   \n",
      "7             boxed warnings    exact-medra    69     NaN   193   \n",
      "8             boxed warnings        negated     0     NaN     3   \n",
      "9             boxed warnings     non-meddra    25     NaN   101   \n",
      "10  warnings and precautions            all   624  3688.0  1828   \n",
      "11  warnings and precautions  discontinuous     9     NaN   341   \n",
      "12  warnings and precautions    exact-medra   624     NaN  1828   \n",
      "13  warnings and precautions        negated     7     NaN    20   \n",
      "14  warnings and precautions     non-meddra   132     NaN  1108   \n",
      "\n",
      "    micro_precision  micro_recall  micro_f1  macro_precision  macro_recall  \\\n",
      "0          0.905612      0.731684  0.809410         0.881586      0.759287   \n",
      "1               NaN      0.118557       NaN              NaN      0.118779   \n",
      "2               NaN      0.731684       NaN              NaN      0.759287   \n",
      "3               NaN      0.468750       NaN              NaN      0.424603   \n",
      "4               NaN      0.373617       NaN              NaN      0.483704   \n",
      "5          0.016002      0.263359  0.030171         0.017596      0.324471   \n",
      "6               NaN      0.060606       NaN              NaN      0.025974   \n",
      "7               NaN      0.263359       NaN              NaN      0.324471   \n",
      "8               NaN      0.000000       NaN              NaN      0.000000   \n",
      "9               NaN      0.198413       NaN              NaN      0.209380   \n",
      "10         0.144712      0.254486  0.184506         0.143903      0.258564   \n",
      "11              NaN      0.025714       NaN              NaN      0.035137   \n",
      "12              NaN      0.254486       NaN              NaN      0.258564   \n",
      "13              NaN      0.259259       NaN              NaN      0.259804   \n",
      "14              NaN      0.106452       NaN              NaN      0.129791   \n",
      "\n",
      "    macro_f1  \n",
      "0   0.823956  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n",
      "5   0.095108  \n",
      "6        NaN  \n",
      "7        NaN  \n",
      "8        NaN  \n",
      "9        NaN  \n",
      "10  0.196530  \n",
      "11       NaN  \n",
      "12       NaN  \n",
      "13       NaN  \n",
      "14       NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:01<00:00, 53.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-4-1106-preview_fatal-prompt-v2_no-system-prompt_temp0_train_run1\n",
      "                     section       ade_type    tp      fp    fn  \\\n",
      "0          adverse reactions            all  3884   389.0  1453   \n",
      "1          adverse reactions  discontinuous    50     NaN   338   \n",
      "2          adverse reactions    exact-medra  3884     NaN  1453   \n",
      "3          adverse reactions        negated    17     NaN    15   \n",
      "4          adverse reactions     non-meddra   437     NaN   738   \n",
      "5             boxed warnings            all    67  4206.0   195   \n",
      "6             boxed warnings  discontinuous     1     NaN    32   \n",
      "7             boxed warnings    exact-medra    67     NaN   195   \n",
      "8             boxed warnings        negated     0     NaN     3   \n",
      "9             boxed warnings     non-meddra    23     NaN   103   \n",
      "10  warnings and precautions            all   622  3651.0  1830   \n",
      "11  warnings and precautions  discontinuous    11     NaN   339   \n",
      "12  warnings and precautions    exact-medra   622     NaN  1830   \n",
      "13  warnings and precautions        negated     7     NaN    20   \n",
      "14  warnings and precautions     non-meddra   132     NaN  1108   \n",
      "\n",
      "    micro_precision  micro_recall  micro_f1  macro_precision  macro_recall  \\\n",
      "0          0.908963      0.727750  0.808325         0.883940      0.754128   \n",
      "1               NaN      0.128866       NaN              NaN      0.129035   \n",
      "2               NaN      0.727750       NaN              NaN      0.754128   \n",
      "3               NaN      0.531250       NaN              NaN      0.488095   \n",
      "4               NaN      0.371915       NaN              NaN      0.484584   \n",
      "5          0.015680      0.255725  0.029548         0.017953      0.320170   \n",
      "6               NaN      0.030303       NaN              NaN      0.012987   \n",
      "7               NaN      0.255725       NaN              NaN      0.320170   \n",
      "8               NaN      0.000000       NaN              NaN      0.000000   \n",
      "9               NaN      0.182540       NaN              NaN      0.202165   \n",
      "10         0.145565      0.253670  0.184981         0.146193      0.257152   \n",
      "11              NaN      0.031429       NaN              NaN      0.037734   \n",
      "12              NaN      0.253670       NaN              NaN      0.257152   \n",
      "13              NaN      0.259259       NaN              NaN      0.259804   \n",
      "14              NaN      0.106452       NaN              NaN      0.129524   \n",
      "\n",
      "    macro_f1  \n",
      "0   0.822647  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n",
      "5   0.099880  \n",
      "6        NaN  \n",
      "7        NaN  \n",
      "8        NaN  \n",
      "9        NaN  \n",
      "10  0.196446  \n",
      "11       NaN  \n",
      "12       NaN  \n",
      "13       NaN  \n",
      "14       NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:01<00:00, 54.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_no-system-prompt_temp0_train_run0\n",
      "                     section       ade_type    tp      fp    fn  \\\n",
      "0          adverse reactions            all  2443   313.0  2894   \n",
      "1          adverse reactions  discontinuous    25     NaN   363   \n",
      "2          adverse reactions    exact-medra  2443     NaN  2894   \n",
      "3          adverse reactions        negated    12     NaN    20   \n",
      "4          adverse reactions     non-meddra   296     NaN   879   \n",
      "5             boxed warnings            all    72  2684.0   190   \n",
      "6             boxed warnings  discontinuous     3     NaN    30   \n",
      "7             boxed warnings    exact-medra    72     NaN   190   \n",
      "8             boxed warnings        negated     1     NaN     2   \n",
      "9             boxed warnings     non-meddra    26     NaN   100   \n",
      "10  warnings and precautions            all   518  2238.0  1934   \n",
      "11  warnings and precautions  discontinuous    12     NaN   338   \n",
      "12  warnings and precautions    exact-medra   518     NaN  1934   \n",
      "13  warnings and precautions        negated     7     NaN    20   \n",
      "14  warnings and precautions     non-meddra   111     NaN  1129   \n",
      "\n",
      "    micro_precision  micro_recall  micro_f1  macro_precision  macro_recall  \\\n",
      "0          0.886430      0.457748  0.603732         0.859126      0.554514   \n",
      "1               NaN      0.064433       NaN              NaN      0.074666   \n",
      "2               NaN      0.457748       NaN              NaN      0.554514   \n",
      "3               NaN      0.375000       NaN              NaN      0.380952   \n",
      "4               NaN      0.251915       NaN              NaN      0.354505   \n",
      "5          0.026125      0.274809  0.047714         0.028453      0.377843   \n",
      "6               NaN      0.090909       NaN              NaN      0.103896   \n",
      "7               NaN      0.274809       NaN              NaN      0.377843   \n",
      "8               NaN      0.333333       NaN              NaN      0.333333   \n",
      "9               NaN      0.206349       NaN              NaN      0.201082   \n",
      "10         0.187954      0.211256  0.198925         0.206445      0.224462   \n",
      "11              NaN      0.034286       NaN              NaN      0.042110   \n",
      "12              NaN      0.211256       NaN              NaN      0.224462   \n",
      "13              NaN      0.259259       NaN              NaN      0.259804   \n",
      "14              NaN      0.089516       NaN              NaN      0.113405   \n",
      "\n",
      "    macro_f1  \n",
      "0   0.638758  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n",
      "5   0.118542  \n",
      "6        NaN  \n",
      "7        NaN  \n",
      "8        NaN  \n",
      "9        NaN  \n",
      "10  0.231083  \n",
      "11       NaN  \n",
      "12       NaN  \n",
      "13       NaN  \n",
      "14       NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:01<00:00, 51.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI_gpt-3.5-turbo-0125_fatal-prompt-v2_no-system-prompt_temp0_train_run1\n",
      "                     section       ade_type    tp      fp    fn  \\\n",
      "0          adverse reactions            all  2591   303.0  2746   \n",
      "1          adverse reactions  discontinuous    25     NaN   363   \n",
      "2          adverse reactions    exact-medra  2591     NaN  2746   \n",
      "3          adverse reactions        negated    12     NaN    20   \n",
      "4          adverse reactions     non-meddra   328     NaN   847   \n",
      "5             boxed warnings            all    72  2822.0   190   \n",
      "6             boxed warnings  discontinuous     2     NaN    31   \n",
      "7             boxed warnings    exact-medra    72     NaN   190   \n",
      "8             boxed warnings        negated     1     NaN     2   \n",
      "9             boxed warnings     non-meddra    27     NaN    99   \n",
      "10  warnings and precautions            all   541  2353.0  1911   \n",
      "11  warnings and precautions  discontinuous    11     NaN   339   \n",
      "12  warnings and precautions    exact-medra   541     NaN  1911   \n",
      "13  warnings and precautions        negated     7     NaN    20   \n",
      "14  warnings and precautions     non-meddra   124     NaN  1116   \n",
      "\n",
      "    micro_precision  micro_recall  micro_f1  macro_precision  macro_recall  \\\n",
      "0          0.895301      0.485479  0.629571         0.858238      0.570654   \n",
      "1               NaN      0.064433       NaN              NaN      0.088414   \n",
      "2               NaN      0.485479       NaN              NaN      0.570654   \n",
      "3               NaN      0.375000       NaN              NaN      0.380952   \n",
      "4               NaN      0.279149       NaN              NaN      0.375312   \n",
      "5          0.024879      0.274809  0.045627         0.028244      0.377477   \n",
      "6               NaN      0.060606       NaN              NaN      0.058442   \n",
      "7               NaN      0.274809       NaN              NaN      0.377477   \n",
      "8               NaN      0.333333       NaN              NaN      0.333333   \n",
      "9               NaN      0.214286       NaN              NaN      0.208658   \n",
      "10         0.186938      0.220636  0.202394         0.202721      0.234538   \n",
      "11              NaN      0.031429       NaN              NaN      0.040325   \n",
      "12              NaN      0.220636       NaN              NaN      0.234538   \n",
      "13              NaN      0.259259       NaN              NaN      0.259804   \n",
      "14              NaN      0.100000       NaN              NaN      0.127009   \n",
      "\n",
      "    macro_f1  \n",
      "0   0.652824  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n",
      "5   0.121156  \n",
      "6        NaN  \n",
      "7        NaN  \n",
      "8        NaN  \n",
      "9        NaN  \n",
      "10  0.232879  \n",
      "11       NaN  \n",
      "12       NaN  \n",
      "13       NaN  \n",
      "14       NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for eval_method in ('strict', 'lenient'):\n",
    "    for run_key, output in outputs.items():\n",
    "        granular_save_filename = 'results/{}_{}_granular.csv'.format(run_key, eval_method)\n",
    "        overall_save_filename = 'results/{}_{}_overall.csv'.format(run_key, eval_method)\n",
    "        \n",
    "        print(run_key)\n",
    "        \n",
    "        results_granular = evaluation_granular(manual_ades, output, lenient=(eval_method=='lenient'))\n",
    "        overall_results = results_granular.groupby(['section','ade_type'])[['tp', 'fp', 'fn']].sum(min_count = 1).reset_index()\n",
    "        overall_results['micro_precision'] = overall_results['tp']/(overall_results['tp']+overall_results['fp'])\n",
    "        overall_results['micro_recall'] = overall_results['tp']/(overall_results['tp']+overall_results['fn'])\n",
    "        overall_results['micro_f1'] = (2 * overall_results['micro_precision'] * overall_results['micro_recall'])/(overall_results['micro_precision'] + overall_results['micro_recall']) # 2*tp_total/(2*tp_total+fp_total+fn_total)\n",
    "        \n",
    "        macro_results = results_granular.groupby(['section', 'ade_type'])[['precision', 'recall', 'f1']].mean(numeric_only=True).reset_index()\n",
    "        overall_results['macro_precision'] = macro_results['precision']\n",
    "        overall_results['macro_recall'] = macro_results['recall']\n",
    "        overall_results['macro_f1'] = macro_results['f1']\n",
    "\n",
    "        allsections_results = results_granular.groupby(['ade_type'])[['tp', 'fp', 'fn']].sum(min_count = 1).reset_index().query(\"ade_type == 'all'\")\n",
    "        allsections_results['micro_precision'] = allsections_results['tp']/(allsections_results['tp']+allsections_results['fp'])\n",
    "        allsections_results['micro_recall'] = allsections_results['tp']/(allsections_results['tp']+allsections_results['fn'])\n",
    "        allsections_results['micro_f1'] = (2 * allsections_results['micro_precision'] * allsections_results['micro_recall'])/(allsections_results['micro_precision'] + overall_results['micro_recall']) # 2*tp_total/(2*tp_total+fp_total+fn_total)\n",
    "        \n",
    "        allsections_macro_results = results_granular.groupby(['ade_type'])[['precision', 'recall', 'f1']].mean(numeric_only=True).reset_index().query(\"ade_type == 'all'\")\n",
    "        allsections_results['macro_precision'] = allsections_macro_results['precision']\n",
    "        allsections_results['macro_recall'] = allsections_macro_results['recall']\n",
    "        allsections_results['macro_f1'] = allsections_macro_results['f1']\n",
    "        allsections_results['section'] = ['all']\n",
    "        \n",
    "        overall_results = pd.concat([overall_results, allsections_results])\n",
    "        overall_results.to_csv(overall_save_filename)\n",
    "        results_granular.to_csv(granular_save_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
